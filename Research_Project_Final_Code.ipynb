{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "id": "bSzPIY-9Tv8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQimZTGKT9Yw",
        "outputId": "b7cc97b1-1c69-40e9-bb66-e82458949aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_GadQCCsFmpy",
        "outputId": "70a70142-30b1-48a6-884c-8328826c0020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.0+cu116.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_scatter-2.1.0%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (9.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.4 MB 4.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.0+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.0+cu116.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_sparse-0.6.15%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.15+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.0+cu116.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_cluster-1.6.0%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-cluster) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-cluster) (1.21.6)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.0+cu116.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_spline_conv-1.2.1%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (873 kB)\n",
            "\u001b[K     |████████████████████████████████| 873 kB 4.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n",
            "\u001b[K     |████████████████████████████████| 564 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.0.2)\n",
            "Collecting psutil>=5.8.0\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 89.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2022.9.24)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773302 sha256=07365bc14a44ebbcfe7555248bca566ec051e3fd35727c3f7df190e2cf96d5a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/a3/20/198928106d3169865ae73afcbd3d3d1796cf6b429b55c65378\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: psutil, torch-geometric\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed psutil-5.9.4 torch-geometric-2.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4dtIyDvUOh1",
        "outputId": "af197e22-0d71-4a4b-db48-563ecdb887c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 68.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 75.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.12.0+cu116.html"
      ],
      "metadata": {
        "id": "sXi_8lSR87hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzC59JL-H7Lh"
      },
      "outputs": [],
      "source": [
        "# !pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.12.0+cu113.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Packages"
      ],
      "metadata": {
        "id": "BQbpokhIUBbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch_geometric.nn import RGCNConv,FastRGCNConv,GCNConv,GATConv\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime as dt\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import matthews_corrcoef"
      ],
      "metadata": {
        "id": "uzGhpCs0UDLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global Variables"
      ],
      "metadata": {
        "id": "jrYoEkI6cdhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root='/content/drive/MyDrive/Twibot-20/'\n",
        "device='cpu'"
      ],
      "metadata": {
        "id": "8Egoa-I4cgsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "i85nkSwfc3iQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_train=pd.read_json('/content/drive/MyDrive/Twibot-20/train.json')\n",
        "\n",
        "df_test=pd.read_json('/content/drive/MyDrive/Twibot-20/test.json')\n",
        "\n",
        "df_support=pd.read_json('/content/drive/MyDrive/Twibot-20/support.json')\n",
        "\n",
        "df_dev=pd.read_json('/content/drive/MyDrive/Twibot-20/dev.json')\n",
        "\n",
        "df_train=df_train.iloc[:,[0,1,2,3,5]]\n",
        "df_test=df_test.iloc[:,[0,1,2,3,5]]\n",
        "df_support=df_support.iloc[:,[0,1,2,3]]\n",
        "df_dev=df_dev.iloc[:,[0,1,2,3,5]]\n",
        "df_support['label']='None'\n",
        "\n",
        "df_data_labeled=pd.concat([df_train,df_dev,df_test],ignore_index=True)\n",
        "df_data=pd.concat([df_train,df_dev,df_test,df_support],ignore_index=True)\n"
      ],
      "metadata": {
        "id": "r9_ZdH2Gc5I2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA"
      ],
      "metadata": {
        "id": "Nztmj6q5vYBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "06ohNTzlvXlh",
        "outputId": "a887fcf3-41b9-49bc-a6e8-bb141c6a001b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    ID                                            profile  \\\n",
              "0             17461978  {'id': '17461978 ', 'id_str': '17461978 ', 'na...   \n",
              "1  1297437077403885568  {'id': '1297437077403885568 ', 'id_str': '1297...   \n",
              "2             17685258  {'id': '17685258 ', 'id_str': '17685258 ', 'na...   \n",
              "3             15750898  {'id': '15750898 ', 'id_str': '15750898 ', 'na...   \n",
              "4           1659167666  {'id': '1659167666 ', 'id_str': '1659167666 ',...   \n",
              "\n",
              "                                               tweet  \\\n",
              "0  [RT @CarnivalCruise: 🎉 Are you ready to see wh...   \n",
              "1                                               None   \n",
              "2  [RT @realDonaldTrump: THANK YOU #RNC2020! http...   \n",
              "3  [A family fears they may have been cheated out...   \n",
              "4  [RT @VonteThePlug: Yeah but he ain’t got one h...   \n",
              "\n",
              "                                            neighbor  label  \n",
              "0                                               None      0  \n",
              "1  {'following': ['170861207', '23970102', '47293...      1  \n",
              "2  {'following': ['46464108', '21536398', '186434...      0  \n",
              "3  {'following': ['2324715174', '24030137', '2336...      0  \n",
              "4  {'following': ['1628313708', '726405625', '130...      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c46000d-610a-443c-ac01-754f29e0ba28\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>profile</th>\n",
              "      <th>tweet</th>\n",
              "      <th>neighbor</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17461978</td>\n",
              "      <td>{'id': '17461978 ', 'id_str': '17461978 ', 'na...</td>\n",
              "      <td>[RT @CarnivalCruise: 🎉 Are you ready to see wh...</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1297437077403885568</td>\n",
              "      <td>{'id': '1297437077403885568 ', 'id_str': '1297...</td>\n",
              "      <td>None</td>\n",
              "      <td>{'following': ['170861207', '23970102', '47293...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17685258</td>\n",
              "      <td>{'id': '17685258 ', 'id_str': '17685258 ', 'na...</td>\n",
              "      <td>[RT @realDonaldTrump: THANK YOU #RNC2020! http...</td>\n",
              "      <td>{'following': ['46464108', '21536398', '186434...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15750898</td>\n",
              "      <td>{'id': '15750898 ', 'id_str': '15750898 ', 'na...</td>\n",
              "      <td>[A family fears they may have been cheated out...</td>\n",
              "      <td>{'following': ['2324715174', '24030137', '2336...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1659167666</td>\n",
              "      <td>{'id': '1659167666 ', 'id_str': '1659167666 ',...</td>\n",
              "      <td>[RT @VonteThePlug: Yeah but he ain’t got one h...</td>\n",
              "      <td>{'following': ['1628313708', '726405625', '130...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c46000d-610a-443c-ac01-754f29e0ba28')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c46000d-610a-443c-ac01-754f29e0ba28 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c46000d-610a-443c-ac01-754f29e0ba28');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DhY_pSDwKU4",
        "outputId": "9c94d68e-6fe6-4921-cec3-64559e2677c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID          8278\n",
              "profile     8278\n",
              "tweet       8223\n",
              "neighbor    7524\n",
              "label       8278\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s684rffJwHx1",
        "outputId": "4ab3a5f7-44f0-4a74-ce9b-c859ddabd8b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    ID                                            profile  \\\n",
              "0  1188812492010487808  {'id': '1188812492010487808 ', 'id_str': '1188...   \n",
              "1            155659213  {'id': '155659213 ', 'id_str': '155659213 ', '...   \n",
              "2            147725246  {'id': '147725246 ', 'id_str': '147725246 ', '...   \n",
              "3  1296248637194895360  {'id': '1296248637194895360 ', 'id_str': '1296...   \n",
              "4           1339835893  {'id': '1339835893 ', 'id_str': '1339835893 ',...   \n",
              "\n",
              "                                               tweet  \\\n",
              "0  [RT @clevelanddotcom: Three Ohio House Republi...   \n",
              "1  [We touch our hair 96 times a day on average, ...   \n",
              "2  ['He Looked Like He Knew What He Was Doing': C...   \n",
              "3  [Estamos abiertos a colaboraciones, por lo cuá...   \n",
              "4  [The suffragists chose purple and gold to repr...   \n",
              "\n",
              "                                            neighbor  label  \n",
              "0                                               None      1  \n",
              "1                                               None      0  \n",
              "2  {'following': ['36734275', '20713061', '755419...      0  \n",
              "3  {'following': ['87818409', '41390292', '140910...      1  \n",
              "4                                               None      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8f3dcd9-45cb-4227-8840-1d9f4576b921\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>profile</th>\n",
              "      <th>tweet</th>\n",
              "      <th>neighbor</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1188812492010487808</td>\n",
              "      <td>{'id': '1188812492010487808 ', 'id_str': '1188...</td>\n",
              "      <td>[RT @clevelanddotcom: Three Ohio House Republi...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>155659213</td>\n",
              "      <td>{'id': '155659213 ', 'id_str': '155659213 ', '...</td>\n",
              "      <td>[We touch our hair 96 times a day on average, ...</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>147725246</td>\n",
              "      <td>{'id': '147725246 ', 'id_str': '147725246 ', '...</td>\n",
              "      <td>['He Looked Like He Knew What He Was Doing': C...</td>\n",
              "      <td>{'following': ['36734275', '20713061', '755419...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1296248637194895360</td>\n",
              "      <td>{'id': '1296248637194895360 ', 'id_str': '1296...</td>\n",
              "      <td>[Estamos abiertos a colaboraciones, por lo cuá...</td>\n",
              "      <td>{'following': ['87818409', '41390292', '140910...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1339835893</td>\n",
              "      <td>{'id': '1339835893 ', 'id_str': '1339835893 ',...</td>\n",
              "      <td>[The suffragists chose purple and gold to repr...</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8f3dcd9-45cb-4227-8840-1d9f4576b921')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b8f3dcd9-45cb-4227-8840-1d9f4576b921 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b8f3dcd9-45cb-4227-8840-1d9f4576b921');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xCjaJ-ZwOEs",
        "outputId": "b20bacd7-3b9a-490e-e0b5-833a63dd9af0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID          1183\n",
              "profile     1183\n",
              "tweet       1173\n",
              "neighbor    1074\n",
              "label       1183\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_support.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Z1kj1NvnwaVo",
        "outputId": "1c34962e-7868-410f-fc26-b7f6bdc529c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    ID                                            profile  \\\n",
              "0  1082775333336768512  {'id': '1082775333336768517 ', 'id_str': '1082...   \n",
              "1  1076983321438142464  {'id': '1076983321438142464 ', 'id_str': '1076...   \n",
              "2  1166391878264246272  {'id': '1166391878264246272 ', 'id_str': '1166...   \n",
              "3            103593224  {'id': '103593224 ', 'id_str': '103593224 ', '...   \n",
              "4  1274010352683016192  {'id': '1274010352683016196 ', 'id_str': '1274...   \n",
              "\n",
              "                                               tweet neighbor label  \n",
              "0  [RT @RandyRRQuaid: #RNC KICKOFF with Randy’s N...     None  None  \n",
              "1  [RT @yogagenie: 02/23/20  ~ @GeneStump1 former...     None  None  \n",
              "2  [@joaocaetano aí sim ⚡\\n, RT @loud_victor: Mai...     None  None  \n",
              "3  [RT @TheDemCoalition: FACT: Seven former Trump...     None  None  \n",
              "4  [Man Ellen isn’t even funny\\nShe literally smi...     None  None  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db9a377c-fba8-4ce5-b51a-0e2fe00c0be4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>profile</th>\n",
              "      <th>tweet</th>\n",
              "      <th>neighbor</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1082775333336768512</td>\n",
              "      <td>{'id': '1082775333336768517 ', 'id_str': '1082...</td>\n",
              "      <td>[RT @RandyRRQuaid: #RNC KICKOFF with Randy’s N...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1076983321438142464</td>\n",
              "      <td>{'id': '1076983321438142464 ', 'id_str': '1076...</td>\n",
              "      <td>[RT @yogagenie: 02/23/20  ~ @GeneStump1 former...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1166391878264246272</td>\n",
              "      <td>{'id': '1166391878264246272 ', 'id_str': '1166...</td>\n",
              "      <td>[@joaocaetano aí sim ⚡\\n, RT @loud_victor: Mai...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>103593224</td>\n",
              "      <td>{'id': '103593224 ', 'id_str': '103593224 ', '...</td>\n",
              "      <td>[RT @TheDemCoalition: FACT: Seven former Trump...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1274010352683016192</td>\n",
              "      <td>{'id': '1274010352683016196 ', 'id_str': '1274...</td>\n",
              "      <td>[Man Ellen isn’t even funny\\nShe literally smi...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db9a377c-fba8-4ce5-b51a-0e2fe00c0be4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-db9a377c-fba8-4ce5-b51a-0e2fe00c0be4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-db9a377c-fba8-4ce5-b51a-0e2fe00c0be4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_support.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kTyXUQ0wadH",
        "outputId": "eb6531fe-c335-4cc2-9892-53e60ea757ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID          217754\n",
              "profile     217746\n",
              "tweet       194297\n",
              "neighbor      1185\n",
              "label       217754\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_dev.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pk8KX3Bqwahz",
        "outputId": "ad76f525-5f46-429b-c52d-2a12f89bdef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    ID                                            profile  \\\n",
              "0  1224667050301255680  {'id': '1224667050301255681 ', 'id_str': '1224...   \n",
              "1            738340405  {'id': '738340405 ', 'id_str': '738340405 ', '...   \n",
              "2            108701392  {'id': '108701392 ', 'id_str': '108701392 ', '...   \n",
              "3             10156532  {'id': '10156532 ', 'id_str': '10156532 ', 'na...   \n",
              "4             17525171  {'id': '17525171 ', 'id_str': '17525171 ', 'na...   \n",
              "\n",
              "                                               tweet  \\\n",
              "0  [@SparklesOnlyme পুরোনো এইদিনের কথা\\n, @Barira...   \n",
              "1  [@barstoolbets @betthehorses @JordanByrne70 @t...   \n",
              "2  [On the job hunt? Don’t let an old LinkedIn pr...   \n",
              "3  [Too cute! Prince George's official christenin...   \n",
              "4  [RT @GCoxVariety: Got questions about the digi...   \n",
              "\n",
              "                                            neighbor  label  \n",
              "0  {'following': ['1118754066937462784', '1018358...      0  \n",
              "1                                               None      1  \n",
              "2                                               None      0  \n",
              "3  {'following': ['137196549', '108407162', '1629...      1  \n",
              "4                                               None      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f03b316a-5691-4db8-a768-c18a9493ce23\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>profile</th>\n",
              "      <th>tweet</th>\n",
              "      <th>neighbor</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1224667050301255680</td>\n",
              "      <td>{'id': '1224667050301255681 ', 'id_str': '1224...</td>\n",
              "      <td>[@SparklesOnlyme পুরোনো এইদিনের কথা\\n, @Barira...</td>\n",
              "      <td>{'following': ['1118754066937462784', '1018358...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>738340405</td>\n",
              "      <td>{'id': '738340405 ', 'id_str': '738340405 ', '...</td>\n",
              "      <td>[@barstoolbets @betthehorses @JordanByrne70 @t...</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>108701392</td>\n",
              "      <td>{'id': '108701392 ', 'id_str': '108701392 ', '...</td>\n",
              "      <td>[On the job hunt? Don’t let an old LinkedIn pr...</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10156532</td>\n",
              "      <td>{'id': '10156532 ', 'id_str': '10156532 ', 'na...</td>\n",
              "      <td>[Too cute! Prince George's official christenin...</td>\n",
              "      <td>{'following': ['137196549', '108407162', '1629...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17525171</td>\n",
              "      <td>{'id': '17525171 ', 'id_str': '17525171 ', 'na...</td>\n",
              "      <td>[RT @GCoxVariety: Got questions about the digi...</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f03b316a-5691-4db8-a768-c18a9493ce23')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f03b316a-5691-4db8-a768-c18a9493ce23 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f03b316a-5691-4db8-a768-c18a9493ce23');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_dev.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_8EwHtpwanA",
        "outputId": "b4f4f47e-39fa-40e1-a7ba-fe6654cf5fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID          2365\n",
              "profile     2365\n",
              "tweet       2350\n",
              "neighbor    2141\n",
              "label       2365\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "VWvyIozmbEBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load labels\n",
        "\n",
        "path = root+'label.pt'\n",
        "if not os.path.isfile(path):\n",
        "  labels=torch.LongTensor(df_data_labeled['label']).to(device)\n",
        "  torch.save(labels, path)\n",
        "else:\n",
        "  labels = torch.load(root+\"label.pt\").to(device)"
      ],
      "metadata": {
        "id": "qhXoCRG_k2k3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load description and preprocess\n",
        "\n",
        "path = root+'description.npy'\n",
        "if not os.path.isfile(path):\n",
        "  description=[]\n",
        "  for i in range (df_data.shape[0]):\n",
        "    if df_data['profile'][i] is None or df_data['profile'][i]['description'] is None:\n",
        "      description.append('None')\n",
        "    else:\n",
        "      description.append(df_data['profile'][i]['description'])\n",
        "  description=np.array(description)\n",
        "  np.save(path,description)\n",
        "else:\n",
        "  description=np.load(path,allow_pickle=True)"
      ],
      "metadata": {
        "id": "BUBnkNp2mdnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tweets and preprocess\n",
        "\n",
        "path = root+'tweets.npy'\n",
        "if not os.path.isfile(path):\n",
        "  tweets=[]\n",
        "  for i in range (df_data.shape[0]):\n",
        "    one_usr_tweets=[]\n",
        "    if df_data['tweet'][i] is None:\n",
        "      one_usr_tweets.append('')\n",
        "    else:\n",
        "      for each in df_data['tweet'][i]:\n",
        "        one_usr_tweets.append(each)\n",
        "    tweets.append(one_usr_tweets)\n",
        "  tweets=np.array(tweets)\n",
        "  np.save(path,tweets)\n",
        "else:\n",
        "  tweets=np.load(path,allow_pickle=True)"
      ],
      "metadata": {
        "id": "8l3V9ffPmduy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# description embedding\n",
        "\n",
        "path = root+\"description_tensor.pt\"\n",
        "if not os.path.isfile(path):\n",
        "  description=np.load(root+'description.npy',allow_pickle=True)\n",
        "  feature_extraction = pipeline('feature-extraction', model=\"distilroberta-base\", tokenizer=\"distilroberta-base\",device=0)\n",
        "  description_vec=[]\n",
        "  for each in tqdm(description):\n",
        "    feature=torch.Tensor(feature_extraction(each))\n",
        "    for (i,tensor) in enumerate(feature[0]):\n",
        "      if i==0:\n",
        "        feature_tensor=tensor\n",
        "      else:\n",
        "        feature_tensor+=tensor\n",
        "    feature_tensor/=feature.shape[1]\n",
        "    description_vec.append(feature_tensor)\n",
        "  description_tensor=torch.stack(description_vec,0).to(device)\n",
        "  torch.save(description_tensor,path)\n",
        "else:\n",
        "  description_tensor=torch.load(root+\"description_tensor.pt\").to(device)"
      ],
      "metadata": {
        "id": "s_VV9ZhamhCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tweet embedding\n",
        "\n",
        "path = root+\"tweets_tensor.pt\"\n",
        "if not os.path.isfile(path):\n",
        "  tweets=np.load(root+\"/tweets.npy\",allow_pickle=True)\n",
        "  print('Loading RoBerta')\n",
        "  feature_extract=pipeline('feature-extraction',model='roberta-base',tokenizer='roberta-base',device=0,padding=True, truncation=True,max_length=500, add_special_tokens = True)\n",
        "  tweets_list=[]\n",
        "  for each_person_tweets in tqdm(tweets):\n",
        "    for j,each_tweet in enumerate(each_person_tweets):\n",
        "      each_tweet_tensor=torch.tensor(feature_extract(each_tweet))\n",
        "      for k,each_word_tensor in enumerate(each_tweet_tensor[0]):\n",
        "        if k==0:\n",
        "          total_word_tensor=each_word_tensor\n",
        "        else:\n",
        "          total_word_tensor+=each_word_tensor\n",
        "      total_word_tensor/=each_tweet_tensor.shape[1]\n",
        "      if j==0:\n",
        "        total_each_person_tweets=total_word_tensor\n",
        "      else:\n",
        "        total_each_person_tweets+=total_word_tensor\n",
        "    total_each_person_tweets/=len(each_person_tweets)\n",
        "    tweets_list.append(total_each_person_tweets)\n",
        "  tweet_tensor=torch.stack(tweets_list).to(device)\n",
        "  torch.save(tweet_tensor,path)\n",
        "else:\n",
        "  tweets_tensor=torch.load(root+\"tweets_tensor.pt\").to(device)"
      ],
      "metadata": {
        "id": "yfEV28ZenVXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# numerical properties embedding\n",
        "\n",
        "path0 = root+'numerical_properties_tensor.pt'\n",
        "if not os.path.isfile(path0):\n",
        "  path0=root\n",
        "  if not os.path.isfile(path+\"followers_count.pt\"):\n",
        "    \n",
        "    # followers count\n",
        "    followers_count=[]\n",
        "    for i in range (df_data.shape[0]):\n",
        "      if df_data['profile'][i] is None or df_data['profile'][i]['followers_count'] is None:\n",
        "        followers_count.append(0)\n",
        "      else:\n",
        "        followers_count.append(df_data['profile'][i]['followers_count'])\n",
        "    followers_count=torch.tensor(np.array(followers_count,dtype=np.float32)).to(device)\n",
        "    torch.save(followers_count,path+\"followers_count.pt\")\n",
        "\n",
        "    # friends count\n",
        "    friends_count=[]\n",
        "    for i in range (df_data.shape[0]):\n",
        "      if df_data['profile'][i] is None or df_data['profile'][i]['friends_count'] is None:\n",
        "        friends_count.append(0)\n",
        "      else:\n",
        "        friends_count.append(df_data['profile'][i]['friends_count'])\n",
        "    friends_count=torch.tensor(np.array(friends_count,dtype=np.float32)).to(device)\n",
        "    torch.save(friends_count,path+'friends_count.pt')\n",
        "\n",
        "    # screen name\n",
        "    screen_name_length=[]\n",
        "    for i in range (df_data.shape[0]):\n",
        "      if df_data['profile'][i] is None or df_data['profile'][i]['screen_name'] is None:\n",
        "        screen_name_length.append(0)\n",
        "      else:\n",
        "        screen_name_length.append(len(df_data['profile'][i]['screen_name']))\n",
        "    screen_name_length=torch.tensor(np.array(screen_name_length,dtype=np.float32)).to(device)\n",
        "    torch.save(screen_name_length,path+'screen_name_length.pt')\n",
        "\n",
        "    # favorites count\n",
        "    favourites_count=[]\n",
        "    for i in range (df_data.shape[0]):\n",
        "      if df_data['profile'][i] is None or df_data['profile'][i]['favourites_count'] is None:\n",
        "        favourites_count.append(0)\n",
        "      else:\n",
        "        favourites_count.append(df_data['profile'][i]['favourites_count'])\n",
        "    favourites_count=torch.tensor(np.array(favourites_count,dtype=np.float32)).to(device)\n",
        "    torch.save(favourites_count,path+'favourites_count.pt')\n",
        "\n",
        "    # active days\n",
        "    active_days=[]\n",
        "    date0=dt.strptime('Tue Sep 1 00:00:00 +0000 2020 ','%a %b %d %X %z %Y ')\n",
        "    for i in range (df_data.shape[0]):\n",
        "      if df_data['profile'][i] is None or df_data['profile'][i]['created_at'] is None:\n",
        "        active_days.append(0)\n",
        "      else:\n",
        "        date=dt.strptime(df_data['profile'][i]['created_at'],'%a %b %d %X %z %Y ')\n",
        "        active_days.append((date0-date).days)\n",
        "    active_days=torch.tensor(np.array(active_days,dtype=np.float32)).to(device)\n",
        "    torch.save(active_days,path+'active_days.pt')\n",
        "\n",
        "    # status count\n",
        "    statuses_count=[]\n",
        "    for i in range (df_data.shape[0]):\n",
        "      if df_data['profile'][i] is None or df_data['profile'][i]['statuses_count'] is None:\n",
        "        statuses_count.append(0)\n",
        "      else:\n",
        "        statuses_count.append(int(df_data['profile'][i]['statuses_count']))\n",
        "    statuses_count=torch.tensor(np.array(statuses_count,dtype=np.float32)).to(device)\n",
        "    torch.save(statuses_count,path+'statuses_count.pt')\n",
        "\n",
        "  else:\n",
        "    active_days=torch.load(path+\"active_days.pt\")\n",
        "    screen_name_length=torch.load(path+\"screen_name_length.pt\")\n",
        "    favourites_count=torch.load(path+\"favourites_count.pt\")\n",
        "    followers_count=torch.load(path+\"followers_count.pt\")\n",
        "    friends_count=torch.load(path+\"friends_count.pt\")\n",
        "    statuses_count=torch.load(path+\"statuses_count.pt\")\n",
        "\n",
        "  active_days=pd.Series(active_days.to('cpu').detach().numpy())\n",
        "  active_days=(active_days-active_days.mean())/active_days.std()\n",
        "  active_days=torch.tensor(np.array(active_days))\n",
        "\n",
        "  screen_name_length=pd.Series(screen_name_length.to('cpu').detach().numpy())\n",
        "  screen_name_length_days=(screen_name_length-screen_name_length.mean())/screen_name_length.std()\n",
        "  screen_name_length_days=torch.tensor(np.array(screen_name_length_days))\n",
        "\n",
        "  favourites_count=pd.Series(favourites_count.to('cpu').detach().numpy())\n",
        "  favourites_count=(favourites_count-favourites_count.mean())/favourites_count.std()\n",
        "  favourites_count=torch.tensor(np.array(favourites_count))\n",
        "\n",
        "  followers_count=pd.Series(followers_count.to('cpu').detach().numpy())\n",
        "  followers_count=(followers_count-followers_count.mean())/followers_count.std()\n",
        "  followers_count=torch.tensor(np.array(followers_count))\n",
        "\n",
        "  friends_count=pd.Series(friends_count.to('cpu').detach().numpy())\n",
        "  friends_count=(friends_count-friends_count.mean())/friends_count.std()\n",
        "  friends_count=torch.tensor(np.array(friends_count))\n",
        "\n",
        "  statuses_count=pd.Series(statuses_count.to('cpu').detach().numpy())\n",
        "  statuses_count=(statuses_count-statuses_count.mean())/statuses_count.std()\n",
        "  statuses_count=torch.tensor(np.array(statuses_count))\n",
        "\n",
        "  numerical_properties=torch.cat((followers_count.reshape([229580,1]),friends_count.reshape([229580,1]),favourites_count.reshape([229580,1]),statuses_count.reshape([229580,1]),screen_name_length_days.reshape([229580,1]),active_days.reshape([229580,1])),1).to(device)\n",
        "  torch.save(numerical_properties,\"/content/drive/MyDrive/Twibot-20/numerical_properties_tensor.pt\")\n",
        "\n",
        "else:\n",
        "  numerical_properties=torch.load(root+\"numerical_properties_tensor.pt\").to(device)"
      ],
      "metadata": {
        "id": "0qffF_2_Vdos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_properties.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c8ZVRtWaX61",
        "outputId": "6983c973-ad8d-42fd-b904-6c4d9f68b51a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([229580, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# categorical properties\n",
        "\n",
        "path = root+'categorical_properties_tensor.pt'\n",
        "if not os.path.isfile(path):\n",
        "  category_properties=[]\n",
        "  properties=['protected','geo_enabled','verified']  \n",
        "  for i in range (df_data.shape[0]):\n",
        "    prop=[]\n",
        "    if df_data['profile'][i] is None:\n",
        "      for i in range(3):\n",
        "        prop.append(0)\n",
        "    else:\n",
        "      for each in properties:\n",
        "        if df_data['profile'][i][each] is None:\n",
        "          prop.append(0)\n",
        "        else:\n",
        "          if df_data['profile'][i][each] == \"True\":\n",
        "            prop.append(1)\n",
        "          else:\n",
        "            prop.append(0)\n",
        "    prop=np.array(prop)\n",
        "    category_properties.append(prop)\n",
        "  category_properties=torch.tensor(np.array(category_properties,dtype=np.float32)).to(device)\n",
        "  torch.save(category_properties,root+'categorical_properties_tensor.pt')\n",
        "\n",
        "else:\n",
        "  category_properties=torch.load(root+\"categorical_properties_tensor.pt\").to(device)"
      ],
      "metadata": {
        "id": "IX1qsg5LciKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_properties"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dx7LMNy4cCOt",
        "outputId": "be625dc7-0842-4a51-c8c7-0c9249e8962b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 1., 0.],\n",
              "        ...,\n",
              "        [1., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build graph\n",
        "\n",
        "path = root+'edge_index.pt'\n",
        "if not os.path.isfile(path):\n",
        "  id2index_dict={id:index for index,id in enumerate(df_data['ID'])}\n",
        "  edge_index=[]\n",
        "  edge_type=[]\n",
        "  for i,relation in enumerate(df_data['neighbor']):\n",
        "    if relation is not None:\n",
        "      for each_id in relation['following']:\n",
        "        try:\n",
        "          target_id=id2index_dict[int(each_id)]\n",
        "        except KeyError:\n",
        "          continue\n",
        "        else:\n",
        "          edge_index.append([i,target_id])\n",
        "        edge_type.append(0)\n",
        "      for each_id in relation['follower']:\n",
        "        try:\n",
        "          target_id=id2index_dict[int(each_id)]\n",
        "        except KeyError:\n",
        "          continue\n",
        "        else:\n",
        "          edge_index.append([i,target_id])\n",
        "        edge_type.append(1)\n",
        "    else:\n",
        "      continue\n",
        "  edge_index=torch.tensor(edge_index,dtype=torch.long).t().contiguous().to(device)\n",
        "  edge_type=torch.tensor(edge_type,dtype=torch.long).to(device)\n",
        "  torch.save(edge_index,root+\"edge_index.pt\")\n",
        "  torch.save(edge_type,root+\"edge_type.pt\")\n",
        "\n",
        "else:\n",
        "  edge_index=torch.load(root+\"edge_index.pt\").to(device)\n",
        "  edge_type=torch.load(root+\"edge_type.pt\").to(device)\n"
      ],
      "metadata": {
        "id": "dJmsdIz2lCsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training - common variables and functions"
      ],
      "metadata": {
        "id": "yl9jaem4w9qC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_idx=range(8278)\n",
        "val_idx=range(8278,8278+2365)\n",
        "test_idx=range(8278+2365,8278+2365+1183)\n",
        "\n",
        "\n",
        "embedding_size = 128\n",
        "dropout = 0.3\n",
        "lr = 1e-3\n",
        "weight_decay= 5e-3\n",
        "\n",
        "epochs=100"
      ],
      "metadata": {
        "id": "Pxn-aWyDmNz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(output, labels):\n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    correct = preds.eq(labels).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)\n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m)==nn.Linear:\n",
        "        nn.init.kaiming_uniform_(m.weight)\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    output = model(description_tensor,tweets_tensor,numerical_properties,category_properties,edge_index,edge_type)\n",
        "    loss_train = loss(output[train_idx], labels[train_idx])\n",
        "    acc_train = accuracy(output[train_idx], labels[train_idx])\n",
        "    acc_val = accuracy(output[val_idx], labels[val_idx])\n",
        "    optimizer.zero_grad()\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "    print('Epoch: {:04d}'.format(epoch+1),\n",
        "        'loss_train: {:.4f}'.format(loss_train.item()),\n",
        "        'acc_train: {:.4f}'.format(acc_train.item()),\n",
        "        'acc_val: {:.4f}'.format(acc_val.item()),)\n",
        "    return acc_train,loss_train\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    output = model(description_tensor,tweets_tensor,numerical_properties,category_properties,edge_index,edge_type)\n",
        "    loss_test = loss(output[test_idx], labels[test_idx])\n",
        "    acc_test = accuracy(output[test_idx], labels[test_idx])\n",
        "    output=output.max(1)[1].to('cpu').detach().numpy()\n",
        "    label=labels.to('cpu').detach().numpy()\n",
        "    f1=f1_score(label[test_idx],output[test_idx])\n",
        "    mcc=matthews_corrcoef(label[test_idx], output[test_idx])\n",
        "    print(\"Test set results:\",\n",
        "            \"test_loss= {:.4f}\".format(loss_test.item()),\n",
        "            \"test_accuracy= {:.4f}\".format(acc_test.item()),\n",
        "            \"f1_score= {:.4f}\".format(f1.item()),\n",
        "            \"mcc= {:.4f}\".format(mcc.item()),\n",
        "            )\n",
        "    return acc_test,loss_test,f1_score"
      ],
      "metadata": {
        "id": "Nd3VxioSj6Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RGCN 1 - Using all the Existing features"
      ],
      "metadata": {
        "id": "G3tXickod3uk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RGCN(nn.Module):\n",
        "    def __init__(self,description_size=768,tweet_size=768,numerical_properties_size=6,categorical_properties_size=3,embedding_dimension=128,dropout=0.3):\n",
        "        super(RGCN, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.linear_relu_description=nn.Sequential(\n",
        "            nn.Linear(description_size,int(embedding_dimension/4)),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_relu_tweet=nn.Sequential(\n",
        "            nn.Linear(tweet_size,int(embedding_dimension/4)),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_relu_numerical_properties=nn.Sequential(\n",
        "            nn.Linear(numerical_properties_size,int(embedding_dimension/4)),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_relu_categorical_properties=nn.Sequential(\n",
        "            nn.Linear(categorical_properties_size,int(embedding_dimension/4)),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        \n",
        "        self.linear_relu_input=nn.Sequential(\n",
        "            nn.Linear(embedding_dimension,embedding_dimension),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        \n",
        "        self.rgcn=RGCNConv(embedding_dimension,embedding_dimension,num_relations=2)\n",
        "        \n",
        "        self.linear_relu_output1=nn.Sequential(\n",
        "            nn.Linear(embedding_dimension,embedding_dimension),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_output2=nn.Linear(embedding_dimension,2)\n",
        "        \n",
        "        \n",
        "        \n",
        "    def forward(self,des,tweet,numerical_properties,categorical_properties,edge_index,edge_type):\n",
        "        d=self.linear_relu_description(des)\n",
        "        t=self.linear_relu_tweet(tweet)\n",
        "        n=self.linear_relu_numerical_properties(numerical_properties)\n",
        "        c=self.linear_relu_categorical_properties(categorical_properties)\n",
        "        x=torch.cat((d,t,n,c),dim=1)\n",
        "        \n",
        "        x=self.linear_relu_input(x)\n",
        "        x=self.rgcn(x,edge_index,edge_type)\n",
        "        x=F.dropout(x,p=self.dropout,training=self.training)\n",
        "        x=self.rgcn(x,edge_index,edge_type)\n",
        "        x=self.linear_relu_output1(x)\n",
        "        x=self.linear_output2(x)\n",
        "            \n",
        "        return x"
      ],
      "metadata": {
        "id": "xaWxa5p1vZs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RGCN(numerical_properties_size=6,categorical_properties_size=3,embedding_dimension=128).to(device)\n",
        "loss=nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train(epoch)\n",
        "    \n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlvO9P2-vZwk",
        "outputId": "ec0328ff-0def-4822-ad83-1afd1d059950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 loss_train: 1.1065 acc_train: 0.5130 acc_val: 0.5201\n",
            "Epoch: 0002 loss_train: 0.8173 acc_train: 0.6698 acc_val: 0.6596\n",
            "Epoch: 0003 loss_train: 0.7959 acc_train: 0.7028 acc_val: 0.7027\n",
            "Epoch: 0004 loss_train: 0.6864 acc_train: 0.7301 acc_val: 0.7214\n",
            "Epoch: 0005 loss_train: 0.6304 acc_train: 0.7470 acc_val: 0.7340\n",
            "Epoch: 0006 loss_train: 0.5882 acc_train: 0.7542 acc_val: 0.7514\n",
            "Epoch: 0007 loss_train: 0.5785 acc_train: 0.7437 acc_val: 0.7332\n",
            "Epoch: 0008 loss_train: 0.5516 acc_train: 0.7511 acc_val: 0.7353\n",
            "Epoch: 0009 loss_train: 0.5526 acc_train: 0.7537 acc_val: 0.7459\n",
            "Epoch: 0010 loss_train: 0.5038 acc_train: 0.7754 acc_val: 0.7674\n",
            "Epoch: 0011 loss_train: 0.5037 acc_train: 0.7856 acc_val: 0.7755\n",
            "Epoch: 0012 loss_train: 0.4893 acc_train: 0.7887 acc_val: 0.7814\n",
            "Epoch: 0013 loss_train: 0.4973 acc_train: 0.7887 acc_val: 0.7899\n",
            "Epoch: 0014 loss_train: 0.4924 acc_train: 0.7938 acc_val: 0.7852\n",
            "Epoch: 0015 loss_train: 0.4826 acc_train: 0.8000 acc_val: 0.7915\n",
            "Epoch: 0016 loss_train: 0.4601 acc_train: 0.8048 acc_val: 0.8017\n",
            "Epoch: 0017 loss_train: 0.4709 acc_train: 0.8033 acc_val: 0.7949\n",
            "Epoch: 0018 loss_train: 0.4504 acc_train: 0.8119 acc_val: 0.7945\n",
            "Epoch: 0019 loss_train: 0.4551 acc_train: 0.8120 acc_val: 0.7958\n",
            "Epoch: 0020 loss_train: 0.4327 acc_train: 0.8125 acc_val: 0.7958\n",
            "Epoch: 0021 loss_train: 0.4300 acc_train: 0.8101 acc_val: 0.7996\n",
            "Epoch: 0022 loss_train: 0.4215 acc_train: 0.8144 acc_val: 0.7975\n",
            "Epoch: 0023 loss_train: 0.4216 acc_train: 0.8218 acc_val: 0.8072\n",
            "Epoch: 0024 loss_train: 0.4055 acc_train: 0.8265 acc_val: 0.8042\n",
            "Epoch: 0025 loss_train: 0.4009 acc_train: 0.8256 acc_val: 0.8063\n",
            "Epoch: 0026 loss_train: 0.4108 acc_train: 0.8275 acc_val: 0.8123\n",
            "Epoch: 0027 loss_train: 0.3952 acc_train: 0.8322 acc_val: 0.8106\n",
            "Epoch: 0028 loss_train: 0.4045 acc_train: 0.8317 acc_val: 0.8118\n",
            "Epoch: 0029 loss_train: 0.3904 acc_train: 0.8349 acc_val: 0.8186\n",
            "Epoch: 0030 loss_train: 0.3848 acc_train: 0.8381 acc_val: 0.8254\n",
            "Epoch: 0031 loss_train: 0.3860 acc_train: 0.8405 acc_val: 0.8207\n",
            "Epoch: 0032 loss_train: 0.3844 acc_train: 0.8388 acc_val: 0.8283\n",
            "Epoch: 0033 loss_train: 0.3785 acc_train: 0.8411 acc_val: 0.8233\n",
            "Epoch: 0034 loss_train: 0.3840 acc_train: 0.8453 acc_val: 0.8224\n",
            "Epoch: 0035 loss_train: 0.3637 acc_train: 0.8455 acc_val: 0.8317\n",
            "Epoch: 0036 loss_train: 0.3630 acc_train: 0.8494 acc_val: 0.8381\n",
            "Epoch: 0037 loss_train: 0.3581 acc_train: 0.8480 acc_val: 0.8393\n",
            "Epoch: 0038 loss_train: 0.3556 acc_train: 0.8495 acc_val: 0.8368\n",
            "Epoch: 0039 loss_train: 0.3531 acc_train: 0.8507 acc_val: 0.8326\n",
            "Epoch: 0040 loss_train: 0.3569 acc_train: 0.8524 acc_val: 0.8402\n",
            "Epoch: 0041 loss_train: 0.3452 acc_train: 0.8540 acc_val: 0.8414\n",
            "Epoch: 0042 loss_train: 0.3491 acc_train: 0.8520 acc_val: 0.8393\n",
            "Epoch: 0043 loss_train: 0.3451 acc_train: 0.8526 acc_val: 0.8431\n",
            "Epoch: 0044 loss_train: 0.3362 acc_train: 0.8576 acc_val: 0.8410\n",
            "Epoch: 0045 loss_train: 0.3520 acc_train: 0.8523 acc_val: 0.8444\n",
            "Epoch: 0046 loss_train: 0.3368 acc_train: 0.8567 acc_val: 0.8482\n",
            "Epoch: 0047 loss_train: 0.3306 acc_train: 0.8601 acc_val: 0.8423\n",
            "Epoch: 0048 loss_train: 0.3344 acc_train: 0.8599 acc_val: 0.8457\n",
            "Epoch: 0049 loss_train: 0.3258 acc_train: 0.8618 acc_val: 0.8490\n",
            "Epoch: 0050 loss_train: 0.3273 acc_train: 0.8616 acc_val: 0.8482\n",
            "Epoch: 0051 loss_train: 0.3273 acc_train: 0.8623 acc_val: 0.8478\n",
            "Epoch: 0052 loss_train: 0.3258 acc_train: 0.8616 acc_val: 0.8469\n",
            "Epoch: 0053 loss_train: 0.3214 acc_train: 0.8614 acc_val: 0.8512\n",
            "Epoch: 0054 loss_train: 0.3169 acc_train: 0.8617 acc_val: 0.8550\n",
            "Epoch: 0055 loss_train: 0.3146 acc_train: 0.8610 acc_val: 0.8507\n",
            "Epoch: 0056 loss_train: 0.3079 acc_train: 0.8682 acc_val: 0.8474\n",
            "Epoch: 0057 loss_train: 0.3127 acc_train: 0.8674 acc_val: 0.8423\n",
            "Epoch: 0058 loss_train: 0.3069 acc_train: 0.8687 acc_val: 0.8516\n",
            "Epoch: 0059 loss_train: 0.3105 acc_train: 0.8670 acc_val: 0.8499\n",
            "Epoch: 0060 loss_train: 0.3038 acc_train: 0.8709 acc_val: 0.8541\n",
            "Epoch: 0061 loss_train: 0.3019 acc_train: 0.8732 acc_val: 0.8541\n",
            "Epoch: 0062 loss_train: 0.3008 acc_train: 0.8719 acc_val: 0.8584\n",
            "Epoch: 0063 loss_train: 0.3007 acc_train: 0.8730 acc_val: 0.8537\n",
            "Epoch: 0064 loss_train: 0.2938 acc_train: 0.8717 acc_val: 0.8626\n",
            "Epoch: 0065 loss_train: 0.2946 acc_train: 0.8730 acc_val: 0.8596\n",
            "Epoch: 0066 loss_train: 0.2948 acc_train: 0.8745 acc_val: 0.8622\n",
            "Epoch: 0067 loss_train: 0.2878 acc_train: 0.8740 acc_val: 0.8584\n",
            "Epoch: 0068 loss_train: 0.2950 acc_train: 0.8734 acc_val: 0.8584\n",
            "Epoch: 0069 loss_train: 0.2874 acc_train: 0.8757 acc_val: 0.8512\n",
            "Epoch: 0070 loss_train: 0.2842 acc_train: 0.8751 acc_val: 0.8579\n",
            "Epoch: 0071 loss_train: 0.2878 acc_train: 0.8768 acc_val: 0.8579\n",
            "Epoch: 0072 loss_train: 0.2890 acc_train: 0.8779 acc_val: 0.8520\n",
            "Epoch: 0073 loss_train: 0.2794 acc_train: 0.8821 acc_val: 0.8596\n",
            "Epoch: 0074 loss_train: 0.2822 acc_train: 0.8815 acc_val: 0.8617\n",
            "Epoch: 0075 loss_train: 0.2770 acc_train: 0.8810 acc_val: 0.8638\n",
            "Epoch: 0076 loss_train: 0.2783 acc_train: 0.8820 acc_val: 0.8643\n",
            "Epoch: 0077 loss_train: 0.2783 acc_train: 0.8803 acc_val: 0.8554\n",
            "Epoch: 0078 loss_train: 0.2691 acc_train: 0.8852 acc_val: 0.8638\n",
            "Epoch: 0079 loss_train: 0.2732 acc_train: 0.8840 acc_val: 0.8613\n",
            "Epoch: 0080 loss_train: 0.2676 acc_train: 0.8846 acc_val: 0.8600\n",
            "Epoch: 0081 loss_train: 0.2666 acc_train: 0.8855 acc_val: 0.8588\n",
            "Epoch: 0082 loss_train: 0.2639 acc_train: 0.8896 acc_val: 0.8567\n",
            "Epoch: 0083 loss_train: 0.2647 acc_train: 0.8893 acc_val: 0.8609\n",
            "Epoch: 0084 loss_train: 0.2654 acc_train: 0.8872 acc_val: 0.8638\n",
            "Epoch: 0085 loss_train: 0.2663 acc_train: 0.8861 acc_val: 0.8596\n",
            "Epoch: 0086 loss_train: 0.2616 acc_train: 0.8890 acc_val: 0.8600\n",
            "Epoch: 0087 loss_train: 0.2622 acc_train: 0.8866 acc_val: 0.8584\n",
            "Epoch: 0088 loss_train: 0.2557 acc_train: 0.8909 acc_val: 0.8545\n",
            "Epoch: 0089 loss_train: 0.2543 acc_train: 0.8935 acc_val: 0.8600\n",
            "Epoch: 0090 loss_train: 0.2560 acc_train: 0.8932 acc_val: 0.8638\n",
            "Epoch: 0091 loss_train: 0.2580 acc_train: 0.8920 acc_val: 0.8575\n",
            "Epoch: 0092 loss_train: 0.2547 acc_train: 0.8931 acc_val: 0.8545\n",
            "Epoch: 0093 loss_train: 0.2551 acc_train: 0.8937 acc_val: 0.8588\n",
            "Epoch: 0094 loss_train: 0.2481 acc_train: 0.8938 acc_val: 0.8643\n",
            "Epoch: 0095 loss_train: 0.2542 acc_train: 0.8931 acc_val: 0.8622\n",
            "Epoch: 0096 loss_train: 0.2480 acc_train: 0.8944 acc_val: 0.8579\n",
            "Epoch: 0097 loss_train: 0.2480 acc_train: 0.8943 acc_val: 0.8596\n",
            "Epoch: 0098 loss_train: 0.2406 acc_train: 0.8974 acc_val: 0.8596\n",
            "Epoch: 0099 loss_train: 0.2431 acc_train: 0.8984 acc_val: 0.8571\n",
            "Epoch: 0100 loss_train: 0.2420 acc_train: 0.8973 acc_val: 0.8567\n",
            "Test set results: test_loss= 0.3437 test_accuracy= 0.8580 f1_score= 0.8721 mcc= 0.7139\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.8580, dtype=torch.float64),\n",
              " tensor(0.3437, grad_fn=<NllLossBackward0>),\n",
              " <function sklearn.metrics._classification.f1_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')>)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RGCN 2 - Using only the Description feature"
      ],
      "metadata": {
        "id": "kgtO8qpId8n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RGCN2(nn.Module):\n",
        "    def __init__(self,description_size=768,tweet_size=768,numerical_properties_size=6,categorical_properties_size=3,embedding_dimension=128,dropout=0.3):\n",
        "        super(RGCN2, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.linear_relu_description=nn.Sequential(\n",
        "            nn.Linear(description_size,int(embedding_dimension)),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_relu_input=nn.Sequential(\n",
        "            nn.Linear(embedding_dimension,embedding_dimension),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_relu_output1=nn.Sequential(\n",
        "            nn.Linear(embedding_dimension,embedding_dimension),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_output2=nn.Linear(embedding_dimension,2)\n",
        "        \n",
        "        self.rgcn=RGCNConv(embedding_dimension,embedding_dimension,num_relations=2)\n",
        "        \n",
        "    def forward(self,des,tweet,numerical_properties,categorical_properties,edge_index,edge_type):\n",
        "        d=self.linear_relu_description(des)\n",
        "        x=d\n",
        "        \n",
        "        x=self.linear_relu_input(x)\n",
        "        x=self.rgcn(x,edge_index,edge_type)\n",
        "        x=F.dropout(x,p=self.dropout,training=self.training)\n",
        "        x=self.rgcn(x,edge_index,edge_type)\n",
        "        x=self.linear_relu_output1(x)\n",
        "        x=self.linear_output2(x)\n",
        "            \n",
        "        return x"
      ],
      "metadata": {
        "id": "IZVjChvyIxet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RGCN2(numerical_properties_size=6,categorical_properties_size=3,embedding_dimension=128).to(device)\n",
        "loss=nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train(epoch)\n",
        "    \n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAC8cQ68Jpji",
        "outputId": "e8b49389-77a2-4aef-9ba3-ccb21275922d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 loss_train: 1.1908 acc_train: 0.4485 acc_val: 0.4693\n",
            "Epoch: 0002 loss_train: 1.1601 acc_train: 0.5600 acc_val: 0.5463\n",
            "Epoch: 0003 loss_train: 0.9610 acc_train: 0.5683 acc_val: 0.5539\n",
            "Epoch: 0004 loss_train: 0.7698 acc_train: 0.6162 acc_val: 0.6118\n",
            "Epoch: 0005 loss_train: 0.7539 acc_train: 0.6309 acc_val: 0.6376\n",
            "Epoch: 0006 loss_train: 0.7594 acc_train: 0.6169 acc_val: 0.6224\n",
            "Epoch: 0007 loss_train: 0.7280 acc_train: 0.5923 acc_val: 0.6030\n",
            "Epoch: 0008 loss_train: 0.6979 acc_train: 0.5820 acc_val: 0.5793\n",
            "Epoch: 0009 loss_train: 0.6787 acc_train: 0.5831 acc_val: 0.5945\n",
            "Epoch: 0010 loss_train: 0.6767 acc_train: 0.5843 acc_val: 0.5805\n",
            "Epoch: 0011 loss_train: 0.6747 acc_train: 0.5975 acc_val: 0.5877\n",
            "Epoch: 0012 loss_train: 0.6725 acc_train: 0.5933 acc_val: 0.5941\n",
            "Epoch: 0013 loss_train: 0.6613 acc_train: 0.6099 acc_val: 0.6042\n",
            "Epoch: 0014 loss_train: 0.6470 acc_train: 0.6245 acc_val: 0.6207\n",
            "Epoch: 0015 loss_train: 0.6393 acc_train: 0.6451 acc_val: 0.6529\n",
            "Epoch: 0016 loss_train: 0.6352 acc_train: 0.6489 acc_val: 0.6469\n",
            "Epoch: 0017 loss_train: 0.6343 acc_train: 0.6487 acc_val: 0.6613\n",
            "Epoch: 0018 loss_train: 0.6362 acc_train: 0.6489 acc_val: 0.6461\n",
            "Epoch: 0019 loss_train: 0.6386 acc_train: 0.6509 acc_val: 0.6503\n",
            "Epoch: 0020 loss_train: 0.6319 acc_train: 0.6475 acc_val: 0.6520\n",
            "Epoch: 0021 loss_train: 0.6246 acc_train: 0.6556 acc_val: 0.6651\n",
            "Epoch: 0022 loss_train: 0.6231 acc_train: 0.6621 acc_val: 0.6727\n",
            "Epoch: 0023 loss_train: 0.6152 acc_train: 0.6741 acc_val: 0.6723\n",
            "Epoch: 0024 loss_train: 0.6140 acc_train: 0.6756 acc_val: 0.6803\n",
            "Epoch: 0025 loss_train: 0.6120 acc_train: 0.6766 acc_val: 0.6774\n",
            "Epoch: 0026 loss_train: 0.6117 acc_train: 0.6744 acc_val: 0.6757\n",
            "Epoch: 0027 loss_train: 0.6057 acc_train: 0.6831 acc_val: 0.6799\n",
            "Epoch: 0028 loss_train: 0.6030 acc_train: 0.6872 acc_val: 0.6808\n",
            "Epoch: 0029 loss_train: 0.5962 acc_train: 0.6970 acc_val: 0.6968\n",
            "Epoch: 0030 loss_train: 0.5940 acc_train: 0.6999 acc_val: 0.7066\n",
            "Epoch: 0031 loss_train: 0.5917 acc_train: 0.6982 acc_val: 0.6926\n",
            "Epoch: 0032 loss_train: 0.5889 acc_train: 0.7048 acc_val: 0.6981\n",
            "Epoch: 0033 loss_train: 0.5827 acc_train: 0.7103 acc_val: 0.7095\n",
            "Epoch: 0034 loss_train: 0.5818 acc_train: 0.7089 acc_val: 0.7078\n",
            "Epoch: 0035 loss_train: 0.5786 acc_train: 0.7058 acc_val: 0.7011\n",
            "Epoch: 0036 loss_train: 0.5771 acc_train: 0.7077 acc_val: 0.7036\n",
            "Epoch: 0037 loss_train: 0.5723 acc_train: 0.7086 acc_val: 0.7006\n",
            "Epoch: 0038 loss_train: 0.5688 acc_train: 0.7137 acc_val: 0.7040\n",
            "Epoch: 0039 loss_train: 0.5652 acc_train: 0.7196 acc_val: 0.7137\n",
            "Epoch: 0040 loss_train: 0.5651 acc_train: 0.7203 acc_val: 0.7142\n",
            "Epoch: 0041 loss_train: 0.5624 acc_train: 0.7243 acc_val: 0.7184\n",
            "Epoch: 0042 loss_train: 0.5615 acc_train: 0.7196 acc_val: 0.7201\n",
            "Epoch: 0043 loss_train: 0.5543 acc_train: 0.7237 acc_val: 0.7192\n",
            "Epoch: 0044 loss_train: 0.5557 acc_train: 0.7280 acc_val: 0.7252\n",
            "Epoch: 0045 loss_train: 0.5560 acc_train: 0.7237 acc_val: 0.7146\n",
            "Epoch: 0046 loss_train: 0.5507 acc_train: 0.7344 acc_val: 0.7214\n",
            "Epoch: 0047 loss_train: 0.5492 acc_train: 0.7324 acc_val: 0.7239\n",
            "Epoch: 0048 loss_train: 0.5454 acc_train: 0.7307 acc_val: 0.7319\n",
            "Epoch: 0049 loss_train: 0.5417 acc_train: 0.7397 acc_val: 0.7307\n",
            "Epoch: 0050 loss_train: 0.5420 acc_train: 0.7375 acc_val: 0.7222\n",
            "Epoch: 0051 loss_train: 0.5386 acc_train: 0.7399 acc_val: 0.7302\n",
            "Epoch: 0052 loss_train: 0.5384 acc_train: 0.7382 acc_val: 0.7311\n",
            "Epoch: 0053 loss_train: 0.5331 acc_train: 0.7410 acc_val: 0.7404\n",
            "Epoch: 0054 loss_train: 0.5360 acc_train: 0.7412 acc_val: 0.7366\n",
            "Epoch: 0055 loss_train: 0.5295 acc_train: 0.7457 acc_val: 0.7395\n",
            "Epoch: 0056 loss_train: 0.5252 acc_train: 0.7518 acc_val: 0.7416\n",
            "Epoch: 0057 loss_train: 0.5239 acc_train: 0.7513 acc_val: 0.7370\n",
            "Epoch: 0058 loss_train: 0.5260 acc_train: 0.7486 acc_val: 0.7353\n",
            "Epoch: 0059 loss_train: 0.5223 acc_train: 0.7531 acc_val: 0.7412\n",
            "Epoch: 0060 loss_train: 0.5204 acc_train: 0.7545 acc_val: 0.7438\n",
            "Epoch: 0061 loss_train: 0.5192 acc_train: 0.7550 acc_val: 0.7345\n",
            "Epoch: 0062 loss_train: 0.5156 acc_train: 0.7557 acc_val: 0.7421\n",
            "Epoch: 0063 loss_train: 0.5118 acc_train: 0.7619 acc_val: 0.7484\n",
            "Epoch: 0064 loss_train: 0.5124 acc_train: 0.7582 acc_val: 0.7433\n",
            "Epoch: 0065 loss_train: 0.5050 acc_train: 0.7654 acc_val: 0.7433\n",
            "Epoch: 0066 loss_train: 0.5090 acc_train: 0.7591 acc_val: 0.7391\n",
            "Epoch: 0067 loss_train: 0.5038 acc_train: 0.7670 acc_val: 0.7425\n",
            "Epoch: 0068 loss_train: 0.5022 acc_train: 0.7635 acc_val: 0.7302\n",
            "Epoch: 0069 loss_train: 0.4984 acc_train: 0.7656 acc_val: 0.7391\n",
            "Epoch: 0070 loss_train: 0.4982 acc_train: 0.7695 acc_val: 0.7353\n",
            "Epoch: 0071 loss_train: 0.4936 acc_train: 0.7704 acc_val: 0.7433\n",
            "Epoch: 0072 loss_train: 0.4945 acc_train: 0.7658 acc_val: 0.7446\n",
            "Epoch: 0073 loss_train: 0.4914 acc_train: 0.7687 acc_val: 0.7391\n",
            "Epoch: 0074 loss_train: 0.4879 acc_train: 0.7729 acc_val: 0.7416\n",
            "Epoch: 0075 loss_train: 0.4858 acc_train: 0.7772 acc_val: 0.7421\n",
            "Epoch: 0076 loss_train: 0.4842 acc_train: 0.7728 acc_val: 0.7421\n",
            "Epoch: 0077 loss_train: 0.4791 acc_train: 0.7791 acc_val: 0.7416\n",
            "Epoch: 0078 loss_train: 0.4789 acc_train: 0.7776 acc_val: 0.7446\n",
            "Epoch: 0079 loss_train: 0.4770 acc_train: 0.7800 acc_val: 0.7501\n",
            "Epoch: 0080 loss_train: 0.4761 acc_train: 0.7845 acc_val: 0.7395\n",
            "Epoch: 0081 loss_train: 0.4725 acc_train: 0.7851 acc_val: 0.7408\n",
            "Epoch: 0082 loss_train: 0.4676 acc_train: 0.7846 acc_val: 0.7378\n",
            "Epoch: 0083 loss_train: 0.4671 acc_train: 0.7842 acc_val: 0.7404\n",
            "Epoch: 0084 loss_train: 0.4645 acc_train: 0.7898 acc_val: 0.7412\n",
            "Epoch: 0085 loss_train: 0.4632 acc_train: 0.7905 acc_val: 0.7421\n",
            "Epoch: 0086 loss_train: 0.4597 acc_train: 0.7886 acc_val: 0.7332\n",
            "Epoch: 0087 loss_train: 0.4576 acc_train: 0.7920 acc_val: 0.7408\n",
            "Epoch: 0088 loss_train: 0.4547 acc_train: 0.7934 acc_val: 0.7412\n",
            "Epoch: 0089 loss_train: 0.4492 acc_train: 0.7962 acc_val: 0.7349\n",
            "Epoch: 0090 loss_train: 0.4475 acc_train: 0.7948 acc_val: 0.7442\n",
            "Epoch: 0091 loss_train: 0.4424 acc_train: 0.7986 acc_val: 0.7362\n",
            "Epoch: 0092 loss_train: 0.4418 acc_train: 0.8004 acc_val: 0.7400\n",
            "Epoch: 0093 loss_train: 0.4388 acc_train: 0.8047 acc_val: 0.7307\n",
            "Epoch: 0094 loss_train: 0.4350 acc_train: 0.8037 acc_val: 0.7336\n",
            "Epoch: 0095 loss_train: 0.4379 acc_train: 0.7995 acc_val: 0.7319\n",
            "Epoch: 0096 loss_train: 0.4333 acc_train: 0.8008 acc_val: 0.7374\n",
            "Epoch: 0097 loss_train: 0.4258 acc_train: 0.8095 acc_val: 0.7349\n",
            "Epoch: 0098 loss_train: 0.4222 acc_train: 0.8112 acc_val: 0.7362\n",
            "Epoch: 0099 loss_train: 0.4211 acc_train: 0.8093 acc_val: 0.7366\n",
            "Epoch: 0100 loss_train: 0.4194 acc_train: 0.8095 acc_val: 0.7383\n",
            "Test set results: test_loss= 0.5685 test_accuracy= 0.7320 f1_score= 0.7681 mcc= 0.4590\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.7320, dtype=torch.float64),\n",
              " tensor(0.5685, grad_fn=<NllLossBackward0>),\n",
              " <function sklearn.metrics._classification.f1_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')>)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RGCN 3 - Using only the Tweets feature"
      ],
      "metadata": {
        "id": "W-UBjwKaeAW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RGCN3(nn.Module):\n",
        "    def __init__(self,description_size=768,tweet_size=768,numerical_properties_size=6,categorical_properties_size=3,embedding_dimension=128,dropout=0.3):\n",
        "        super(RGCN3, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.linear_relu_tweet=nn.Sequential(\n",
        "            nn.Linear(tweet_size,int(embedding_dimension)),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_relu_input=nn.Sequential(\n",
        "            nn.Linear(embedding_dimension,embedding_dimension),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_relu_output1=nn.Sequential(\n",
        "            nn.Linear(embedding_dimension,embedding_dimension),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_output2=nn.Linear(embedding_dimension,2)\n",
        "        \n",
        "        self.rgcn=RGCNConv(embedding_dimension,embedding_dimension,num_relations=2)\n",
        "        \n",
        "    def forward(self,des,tweet,numerical_properties,categorical_properties,edge_index,edge_type):\n",
        "        t=self.linear_relu_tweet(tweet)\n",
        "        x=t\n",
        "        \n",
        "        x=self.linear_relu_input(x)\n",
        "        x=self.rgcn(x,edge_index,edge_type)\n",
        "        x=F.dropout(x,p=self.dropout,training=self.training)\n",
        "        x=self.rgcn(x,edge_index,edge_type)\n",
        "        x=self.linear_relu_output1(x)\n",
        "        x=self.linear_output2(x)\n",
        "            \n",
        "        return x"
      ],
      "metadata": {
        "id": "9egRkEBJjdj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RGCN3(numerical_properties_size=6,categorical_properties_size=3,embedding_dimension=128).to(device)\n",
        "loss=nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train(epoch)\n",
        "    \n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UrHqi9Jjd3L",
        "outputId": "9755ee1a-880f-4ec8-f4b6-f33407b2dd98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 loss_train: 0.8508 acc_train: 0.5062 acc_val: 0.4913\n",
            "Epoch: 0002 loss_train: 1.0598 acc_train: 0.5605 acc_val: 0.5531\n",
            "Epoch: 0003 loss_train: 0.8289 acc_train: 0.6097 acc_val: 0.5852\n",
            "Epoch: 0004 loss_train: 0.7454 acc_train: 0.6306 acc_val: 0.6233\n",
            "Epoch: 0005 loss_train: 0.7058 acc_train: 0.6224 acc_val: 0.6279\n",
            "Epoch: 0006 loss_train: 0.6915 acc_train: 0.6001 acc_val: 0.6085\n",
            "Epoch: 0007 loss_train: 0.6743 acc_train: 0.5912 acc_val: 0.5797\n",
            "Epoch: 0008 loss_train: 0.6627 acc_train: 0.5928 acc_val: 0.5979\n",
            "Epoch: 0009 loss_train: 0.6625 acc_train: 0.5878 acc_val: 0.5776\n",
            "Epoch: 0010 loss_train: 0.6618 acc_train: 0.5890 acc_val: 0.5751\n",
            "Epoch: 0011 loss_train: 0.6525 acc_train: 0.5936 acc_val: 0.5793\n",
            "Epoch: 0012 loss_train: 0.6421 acc_train: 0.6117 acc_val: 0.5979\n",
            "Epoch: 0013 loss_train: 0.6326 acc_train: 0.6403 acc_val: 0.6342\n",
            "Epoch: 0014 loss_train: 0.6289 acc_train: 0.6572 acc_val: 0.6545\n",
            "Epoch: 0015 loss_train: 0.6261 acc_train: 0.6475 acc_val: 0.6507\n",
            "Epoch: 0016 loss_train: 0.6292 acc_train: 0.6432 acc_val: 0.6457\n",
            "Epoch: 0017 loss_train: 0.6249 acc_train: 0.6441 acc_val: 0.6533\n",
            "Epoch: 0018 loss_train: 0.6190 acc_train: 0.6523 acc_val: 0.6554\n",
            "Epoch: 0019 loss_train: 0.6152 acc_train: 0.6561 acc_val: 0.6605\n",
            "Epoch: 0020 loss_train: 0.6087 acc_train: 0.6689 acc_val: 0.6748\n",
            "Epoch: 0021 loss_train: 0.6046 acc_train: 0.6729 acc_val: 0.6799\n",
            "Epoch: 0022 loss_train: 0.5994 acc_train: 0.6795 acc_val: 0.6753\n",
            "Epoch: 0023 loss_train: 0.5970 acc_train: 0.6799 acc_val: 0.6715\n",
            "Epoch: 0024 loss_train: 0.5907 acc_train: 0.6893 acc_val: 0.6850\n",
            "Epoch: 0025 loss_train: 0.5889 acc_train: 0.6939 acc_val: 0.6956\n",
            "Epoch: 0026 loss_train: 0.5820 acc_train: 0.7008 acc_val: 0.7121\n",
            "Epoch: 0027 loss_train: 0.5819 acc_train: 0.6988 acc_val: 0.7108\n",
            "Epoch: 0028 loss_train: 0.5775 acc_train: 0.7060 acc_val: 0.7082\n",
            "Epoch: 0029 loss_train: 0.5778 acc_train: 0.6978 acc_val: 0.7049\n",
            "Epoch: 0030 loss_train: 0.5734 acc_train: 0.7066 acc_val: 0.7142\n",
            "Epoch: 0031 loss_train: 0.5685 acc_train: 0.7085 acc_val: 0.7154\n",
            "Epoch: 0032 loss_train: 0.5683 acc_train: 0.7075 acc_val: 0.7188\n",
            "Epoch: 0033 loss_train: 0.5634 acc_train: 0.7171 acc_val: 0.7125\n",
            "Epoch: 0034 loss_train: 0.5624 acc_train: 0.7159 acc_val: 0.7205\n",
            "Epoch: 0035 loss_train: 0.5613 acc_train: 0.7151 acc_val: 0.7222\n",
            "Epoch: 0036 loss_train: 0.5561 acc_train: 0.7211 acc_val: 0.7243\n",
            "Epoch: 0037 loss_train: 0.5541 acc_train: 0.7232 acc_val: 0.7159\n",
            "Epoch: 0038 loss_train: 0.5540 acc_train: 0.7251 acc_val: 0.7239\n",
            "Epoch: 0039 loss_train: 0.5504 acc_train: 0.7304 acc_val: 0.7298\n",
            "Epoch: 0040 loss_train: 0.5441 acc_train: 0.7346 acc_val: 0.7383\n",
            "Epoch: 0041 loss_train: 0.5422 acc_train: 0.7344 acc_val: 0.7349\n",
            "Epoch: 0042 loss_train: 0.5386 acc_train: 0.7336 acc_val: 0.7302\n",
            "Epoch: 0043 loss_train: 0.5332 acc_train: 0.7421 acc_val: 0.7395\n",
            "Epoch: 0044 loss_train: 0.5333 acc_train: 0.7404 acc_val: 0.7450\n",
            "Epoch: 0045 loss_train: 0.5330 acc_train: 0.7386 acc_val: 0.7459\n",
            "Epoch: 0046 loss_train: 0.5278 acc_train: 0.7475 acc_val: 0.7421\n",
            "Epoch: 0047 loss_train: 0.5244 acc_train: 0.7472 acc_val: 0.7510\n",
            "Epoch: 0048 loss_train: 0.5197 acc_train: 0.7522 acc_val: 0.7480\n",
            "Epoch: 0049 loss_train: 0.5187 acc_train: 0.7499 acc_val: 0.7581\n",
            "Epoch: 0050 loss_train: 0.5136 acc_train: 0.7531 acc_val: 0.7518\n",
            "Epoch: 0051 loss_train: 0.5111 acc_train: 0.7578 acc_val: 0.7590\n",
            "Epoch: 0052 loss_train: 0.5093 acc_train: 0.7562 acc_val: 0.7615\n",
            "Epoch: 0053 loss_train: 0.5072 acc_train: 0.7563 acc_val: 0.7649\n",
            "Epoch: 0054 loss_train: 0.5043 acc_train: 0.7603 acc_val: 0.7590\n",
            "Epoch: 0055 loss_train: 0.5016 acc_train: 0.7607 acc_val: 0.7649\n",
            "Epoch: 0056 loss_train: 0.4993 acc_train: 0.7618 acc_val: 0.7619\n",
            "Epoch: 0057 loss_train: 0.4976 acc_train: 0.7585 acc_val: 0.7581\n",
            "Epoch: 0058 loss_train: 0.4946 acc_train: 0.7671 acc_val: 0.7670\n",
            "Epoch: 0059 loss_train: 0.4905 acc_train: 0.7653 acc_val: 0.7700\n",
            "Epoch: 0060 loss_train: 0.4892 acc_train: 0.7677 acc_val: 0.7674\n",
            "Epoch: 0061 loss_train: 0.4855 acc_train: 0.7699 acc_val: 0.7670\n",
            "Epoch: 0062 loss_train: 0.4832 acc_train: 0.7720 acc_val: 0.7662\n",
            "Epoch: 0063 loss_train: 0.4838 acc_train: 0.7710 acc_val: 0.7696\n",
            "Epoch: 0064 loss_train: 0.4814 acc_train: 0.7736 acc_val: 0.7666\n",
            "Epoch: 0065 loss_train: 0.4830 acc_train: 0.7745 acc_val: 0.7687\n",
            "Epoch: 0066 loss_train: 0.4820 acc_train: 0.7710 acc_val: 0.7679\n",
            "Epoch: 0067 loss_train: 0.4780 acc_train: 0.7742 acc_val: 0.7636\n",
            "Epoch: 0068 loss_train: 0.4751 acc_train: 0.7805 acc_val: 0.7767\n",
            "Epoch: 0069 loss_train: 0.4756 acc_train: 0.7763 acc_val: 0.7746\n",
            "Epoch: 0070 loss_train: 0.4762 acc_train: 0.7728 acc_val: 0.7666\n",
            "Epoch: 0071 loss_train: 0.4702 acc_train: 0.7823 acc_val: 0.7725\n",
            "Epoch: 0072 loss_train: 0.4689 acc_train: 0.7788 acc_val: 0.7776\n",
            "Epoch: 0073 loss_train: 0.4707 acc_train: 0.7803 acc_val: 0.7704\n",
            "Epoch: 0074 loss_train: 0.4651 acc_train: 0.7851 acc_val: 0.7780\n",
            "Epoch: 0075 loss_train: 0.4650 acc_train: 0.7822 acc_val: 0.7666\n",
            "Epoch: 0076 loss_train: 0.4638 acc_train: 0.7838 acc_val: 0.7776\n",
            "Epoch: 0077 loss_train: 0.4623 acc_train: 0.7857 acc_val: 0.7670\n",
            "Epoch: 0078 loss_train: 0.4598 acc_train: 0.7863 acc_val: 0.7772\n",
            "Epoch: 0079 loss_train: 0.4611 acc_train: 0.7844 acc_val: 0.7767\n",
            "Epoch: 0080 loss_train: 0.4609 acc_train: 0.7871 acc_val: 0.7717\n",
            "Epoch: 0081 loss_train: 0.4582 acc_train: 0.7850 acc_val: 0.7763\n",
            "Epoch: 0082 loss_train: 0.4552 acc_train: 0.7905 acc_val: 0.7734\n",
            "Epoch: 0083 loss_train: 0.4561 acc_train: 0.7878 acc_val: 0.7717\n",
            "Epoch: 0084 loss_train: 0.4572 acc_train: 0.7874 acc_val: 0.7763\n",
            "Epoch: 0085 loss_train: 0.4532 acc_train: 0.7932 acc_val: 0.7751\n",
            "Epoch: 0086 loss_train: 0.4519 acc_train: 0.7952 acc_val: 0.7767\n",
            "Epoch: 0087 loss_train: 0.4503 acc_train: 0.7927 acc_val: 0.7772\n",
            "Epoch: 0088 loss_train: 0.4510 acc_train: 0.7935 acc_val: 0.7784\n",
            "Epoch: 0089 loss_train: 0.4510 acc_train: 0.7923 acc_val: 0.7755\n",
            "Epoch: 0090 loss_train: 0.4496 acc_train: 0.7925 acc_val: 0.7729\n",
            "Epoch: 0091 loss_train: 0.4481 acc_train: 0.7942 acc_val: 0.7729\n",
            "Epoch: 0092 loss_train: 0.4490 acc_train: 0.7961 acc_val: 0.7717\n",
            "Epoch: 0093 loss_train: 0.4467 acc_train: 0.7969 acc_val: 0.7763\n",
            "Epoch: 0094 loss_train: 0.4420 acc_train: 0.7985 acc_val: 0.7797\n",
            "Epoch: 0095 loss_train: 0.4434 acc_train: 0.7986 acc_val: 0.7810\n",
            "Epoch: 0096 loss_train: 0.4408 acc_train: 0.7950 acc_val: 0.7759\n",
            "Epoch: 0097 loss_train: 0.4405 acc_train: 0.8000 acc_val: 0.7805\n",
            "Epoch: 0098 loss_train: 0.4406 acc_train: 0.8014 acc_val: 0.7772\n",
            "Epoch: 0099 loss_train: 0.4404 acc_train: 0.8013 acc_val: 0.7759\n",
            "Epoch: 0100 loss_train: 0.4382 acc_train: 0.7987 acc_val: 0.7810\n",
            "Test set results: test_loss= 0.4959 test_accuracy= 0.7701 f1_score= 0.7824 mcc= 0.5397\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.7701, dtype=torch.float64),\n",
              " tensor(0.4959, grad_fn=<NllLossBackward0>),\n",
              " <function sklearn.metrics._classification.f1_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')>)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RGCN 4 - Using the Numerical Properties feature"
      ],
      "metadata": {
        "id": "-xKu37mEeG1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RGCN4(nn.Module):\n",
        "    def __init__(self,description_size=768,tweet_size=768,numerical_properties_size=6,categorical_properties_size=3,embedding_dimension=128,dropout=0.3):\n",
        "        super(RGCN4, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.linear_relu_numerical_properties=nn.Sequential(\n",
        "            nn.Linear(numerical_properties_size,int(embedding_dimension)),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_relu_input=nn.Sequential(\n",
        "            nn.Linear(embedding_dimension,embedding_dimension),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_relu_output1=nn.Sequential(\n",
        "            nn.Linear(embedding_dimension,embedding_dimension),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_output2=nn.Linear(embedding_dimension,2)\n",
        "        \n",
        "        self.rgcn=RGCNConv(embedding_dimension,embedding_dimension,num_relations=2)\n",
        "        \n",
        "    def forward(self,des,tweet,numerical_properties,categorical_properties,edge_index,edge_type):\n",
        "        n=self.linear_relu_numerical_properties(numerical_properties)\n",
        "        x=n\n",
        "        \n",
        "        x=self.linear_relu_input(x)\n",
        "        x=self.rgcn(x,edge_index,edge_type)\n",
        "        x=F.dropout(x,p=self.dropout,training=self.training)\n",
        "        x=self.rgcn(x,edge_index,edge_type)\n",
        "        x=self.linear_relu_output1(x)\n",
        "        x=self.linear_output2(x)\n",
        "            \n",
        "        return x"
      ],
      "metadata": {
        "id": "Yf1EvWmblFSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RGCN4(numerical_properties_size=6,categorical_properties_size=3,embedding_dimension=128).to(device)\n",
        "loss=nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train(epoch)\n",
        "    \n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEXMPNcWlFbI",
        "outputId": "7d5dc9aa-3f11-40d2-c057-54e21672a87d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 loss_train: 1.4224 acc_train: 0.4769 acc_val: 0.4613\n",
            "Epoch: 0002 loss_train: 1.1911 acc_train: 0.5900 acc_val: 0.5865\n",
            "Epoch: 0003 loss_train: 0.9963 acc_train: 0.6416 acc_val: 0.6393\n",
            "Epoch: 0004 loss_train: 1.0088 acc_train: 0.6404 acc_val: 0.6516\n",
            "Epoch: 0005 loss_train: 0.9357 acc_train: 0.6369 acc_val: 0.6364\n",
            "Epoch: 0006 loss_train: 0.8490 acc_train: 0.6476 acc_val: 0.6414\n",
            "Epoch: 0007 loss_train: 0.8009 acc_train: 0.6504 acc_val: 0.6469\n",
            "Epoch: 0008 loss_train: 0.7811 acc_train: 0.6435 acc_val: 0.6431\n",
            "Epoch: 0009 loss_train: 0.7687 acc_train: 0.6288 acc_val: 0.6338\n",
            "Epoch: 0010 loss_train: 0.7514 acc_train: 0.6264 acc_val: 0.6262\n",
            "Epoch: 0011 loss_train: 0.7522 acc_train: 0.6312 acc_val: 0.6220\n",
            "Epoch: 0012 loss_train: 0.6986 acc_train: 0.6477 acc_val: 0.6283\n",
            "Epoch: 0013 loss_train: 0.6976 acc_train: 0.6512 acc_val: 0.6414\n",
            "Epoch: 0014 loss_train: 0.6864 acc_train: 0.6566 acc_val: 0.6503\n",
            "Epoch: 0015 loss_train: 0.6789 acc_train: 0.6636 acc_val: 0.6478\n",
            "Epoch: 0016 loss_train: 0.7013 acc_train: 0.6616 acc_val: 0.6469\n",
            "Epoch: 0017 loss_train: 0.6752 acc_train: 0.6731 acc_val: 0.6584\n",
            "Epoch: 0018 loss_train: 0.6542 acc_train: 0.6818 acc_val: 0.6744\n",
            "Epoch: 0019 loss_train: 0.6704 acc_train: 0.6807 acc_val: 0.6808\n",
            "Epoch: 0020 loss_train: 0.6464 acc_train: 0.6839 acc_val: 0.6689\n",
            "Epoch: 0021 loss_train: 0.6398 acc_train: 0.6796 acc_val: 0.6841\n",
            "Epoch: 0022 loss_train: 0.6296 acc_train: 0.6849 acc_val: 0.6791\n",
            "Epoch: 0023 loss_train: 0.6250 acc_train: 0.6869 acc_val: 0.6905\n",
            "Epoch: 0024 loss_train: 0.6213 acc_train: 0.6869 acc_val: 0.6753\n",
            "Epoch: 0025 loss_train: 0.6066 acc_train: 0.6846 acc_val: 0.6770\n",
            "Epoch: 0026 loss_train: 0.6062 acc_train: 0.6930 acc_val: 0.6833\n",
            "Epoch: 0027 loss_train: 0.6252 acc_train: 0.6791 acc_val: 0.6744\n",
            "Epoch: 0028 loss_train: 0.6117 acc_train: 0.6897 acc_val: 0.6850\n",
            "Epoch: 0029 loss_train: 0.6021 acc_train: 0.6876 acc_val: 0.6808\n",
            "Epoch: 0030 loss_train: 0.6266 acc_train: 0.6836 acc_val: 0.6702\n",
            "Epoch: 0031 loss_train: 0.6107 acc_train: 0.6936 acc_val: 0.6943\n",
            "Epoch: 0032 loss_train: 0.5991 acc_train: 0.6973 acc_val: 0.6922\n",
            "Epoch: 0033 loss_train: 0.6173 acc_train: 0.6959 acc_val: 0.6892\n",
            "Epoch: 0034 loss_train: 0.5956 acc_train: 0.6994 acc_val: 0.6939\n",
            "Epoch: 0035 loss_train: 0.5986 acc_train: 0.6934 acc_val: 0.6829\n",
            "Epoch: 0036 loss_train: 0.5784 acc_train: 0.7049 acc_val: 0.6947\n",
            "Epoch: 0037 loss_train: 0.5897 acc_train: 0.7040 acc_val: 0.6951\n",
            "Epoch: 0038 loss_train: 0.5804 acc_train: 0.7077 acc_val: 0.6973\n",
            "Epoch: 0039 loss_train: 0.5893 acc_train: 0.7034 acc_val: 0.6896\n",
            "Epoch: 0040 loss_train: 0.5798 acc_train: 0.7065 acc_val: 0.7011\n",
            "Epoch: 0041 loss_train: 0.5865 acc_train: 0.7019 acc_val: 0.6850\n",
            "Epoch: 0042 loss_train: 0.5829 acc_train: 0.7019 acc_val: 0.7032\n",
            "Epoch: 0043 loss_train: 0.5874 acc_train: 0.7032 acc_val: 0.6913\n",
            "Epoch: 0044 loss_train: 0.5724 acc_train: 0.7045 acc_val: 0.6964\n",
            "Epoch: 0045 loss_train: 0.5760 acc_train: 0.7135 acc_val: 0.6968\n",
            "Epoch: 0046 loss_train: 0.5823 acc_train: 0.7122 acc_val: 0.6964\n",
            "Epoch: 0047 loss_train: 0.5671 acc_train: 0.7102 acc_val: 0.6981\n",
            "Epoch: 0048 loss_train: 0.5708 acc_train: 0.7174 acc_val: 0.7032\n",
            "Epoch: 0049 loss_train: 0.5700 acc_train: 0.7108 acc_val: 0.6956\n",
            "Epoch: 0050 loss_train: 0.5699 acc_train: 0.7106 acc_val: 0.7044\n",
            "Epoch: 0051 loss_train: 0.5677 acc_train: 0.7112 acc_val: 0.6973\n",
            "Epoch: 0052 loss_train: 0.5641 acc_train: 0.7154 acc_val: 0.7015\n",
            "Epoch: 0053 loss_train: 0.5617 acc_train: 0.7122 acc_val: 0.7044\n",
            "Epoch: 0054 loss_train: 0.5679 acc_train: 0.7147 acc_val: 0.7015\n",
            "Epoch: 0055 loss_train: 0.5766 acc_train: 0.7191 acc_val: 0.7036\n",
            "Epoch: 0056 loss_train: 0.5574 acc_train: 0.7209 acc_val: 0.7112\n",
            "Epoch: 0057 loss_train: 0.5631 acc_train: 0.7195 acc_val: 0.6989\n",
            "Epoch: 0058 loss_train: 0.5627 acc_train: 0.7161 acc_val: 0.7078\n",
            "Epoch: 0059 loss_train: 0.5622 acc_train: 0.7158 acc_val: 0.7023\n",
            "Epoch: 0060 loss_train: 0.5549 acc_train: 0.7197 acc_val: 0.7078\n",
            "Epoch: 0061 loss_train: 0.5663 acc_train: 0.7116 acc_val: 0.7015\n",
            "Epoch: 0062 loss_train: 0.5572 acc_train: 0.7182 acc_val: 0.6960\n",
            "Epoch: 0063 loss_train: 0.5566 acc_train: 0.7166 acc_val: 0.7091\n",
            "Epoch: 0064 loss_train: 0.5563 acc_train: 0.7194 acc_val: 0.7066\n",
            "Epoch: 0065 loss_train: 0.5524 acc_train: 0.7214 acc_val: 0.7082\n",
            "Epoch: 0066 loss_train: 0.5503 acc_train: 0.7177 acc_val: 0.6960\n",
            "Epoch: 0067 loss_train: 0.5543 acc_train: 0.7199 acc_val: 0.7099\n",
            "Epoch: 0068 loss_train: 0.5516 acc_train: 0.7156 acc_val: 0.7070\n",
            "Epoch: 0069 loss_train: 0.5533 acc_train: 0.7245 acc_val: 0.7104\n",
            "Epoch: 0070 loss_train: 0.5566 acc_train: 0.7218 acc_val: 0.7104\n",
            "Epoch: 0071 loss_train: 0.5441 acc_train: 0.7248 acc_val: 0.7074\n",
            "Epoch: 0072 loss_train: 0.5504 acc_train: 0.7179 acc_val: 0.7070\n",
            "Epoch: 0073 loss_train: 0.5481 acc_train: 0.7255 acc_val: 0.7116\n",
            "Epoch: 0074 loss_train: 0.5446 acc_train: 0.7223 acc_val: 0.7070\n",
            "Epoch: 0075 loss_train: 0.5472 acc_train: 0.7231 acc_val: 0.7121\n",
            "Epoch: 0076 loss_train: 0.5520 acc_train: 0.7200 acc_val: 0.7104\n",
            "Epoch: 0077 loss_train: 0.5439 acc_train: 0.7242 acc_val: 0.7070\n",
            "Epoch: 0078 loss_train: 0.5470 acc_train: 0.7253 acc_val: 0.7129\n",
            "Epoch: 0079 loss_train: 0.5395 acc_train: 0.7266 acc_val: 0.7133\n",
            "Epoch: 0080 loss_train: 0.5479 acc_train: 0.7265 acc_val: 0.7091\n",
            "Epoch: 0081 loss_train: 0.5390 acc_train: 0.7306 acc_val: 0.7260\n",
            "Epoch: 0082 loss_train: 0.5463 acc_train: 0.7271 acc_val: 0.7066\n",
            "Epoch: 0083 loss_train: 0.5445 acc_train: 0.7214 acc_val: 0.7032\n",
            "Epoch: 0084 loss_train: 0.5393 acc_train: 0.7253 acc_val: 0.7112\n",
            "Epoch: 0085 loss_train: 0.5430 acc_train: 0.7304 acc_val: 0.7137\n",
            "Epoch: 0086 loss_train: 0.5396 acc_train: 0.7280 acc_val: 0.6998\n",
            "Epoch: 0087 loss_train: 0.5389 acc_train: 0.7301 acc_val: 0.7053\n",
            "Epoch: 0088 loss_train: 0.5351 acc_train: 0.7346 acc_val: 0.7108\n",
            "Epoch: 0089 loss_train: 0.5348 acc_train: 0.7302 acc_val: 0.7222\n",
            "Epoch: 0090 loss_train: 0.5331 acc_train: 0.7323 acc_val: 0.7091\n",
            "Epoch: 0091 loss_train: 0.5331 acc_train: 0.7331 acc_val: 0.7036\n",
            "Epoch: 0092 loss_train: 0.5336 acc_train: 0.7321 acc_val: 0.7116\n",
            "Epoch: 0093 loss_train: 0.5358 acc_train: 0.7290 acc_val: 0.7121\n",
            "Epoch: 0094 loss_train: 0.5310 acc_train: 0.7324 acc_val: 0.7180\n",
            "Epoch: 0095 loss_train: 0.5345 acc_train: 0.7339 acc_val: 0.7125\n",
            "Epoch: 0096 loss_train: 0.5328 acc_train: 0.7293 acc_val: 0.7129\n",
            "Epoch: 0097 loss_train: 0.5261 acc_train: 0.7330 acc_val: 0.7104\n",
            "Epoch: 0098 loss_train: 0.5343 acc_train: 0.7273 acc_val: 0.7116\n",
            "Epoch: 0099 loss_train: 0.5324 acc_train: 0.7335 acc_val: 0.7066\n",
            "Epoch: 0100 loss_train: 0.5255 acc_train: 0.7333 acc_val: 0.7108\n",
            "Test set results: test_loss= 0.5451 test_accuracy= 0.7287 f1_score= 0.7775 mcc= 0.4598\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.7287, dtype=torch.float64),\n",
              " tensor(0.5451, grad_fn=<NllLossBackward0>),\n",
              " <function sklearn.metrics._classification.f1_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')>)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RGCN5 - Using the Categorical Properties feature"
      ],
      "metadata": {
        "id": "aHrD-NhPelFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RGCN5(nn.Module):\n",
        "    def __init__(self,description_size=768,tweet_size=768,numerical_properties_size=6,categorical_properties_size=3,embedding_dimension=128,dropout=0.3):\n",
        "        super(RGCN5, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.linear_relu_categorical_properties=nn.Sequential(\n",
        "            nn.Linear(categorical_properties_size,int(embedding_dimension)),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_relu_input=nn.Sequential(\n",
        "            nn.Linear(embedding_dimension,embedding_dimension),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_relu_output1=nn.Sequential(\n",
        "            nn.Linear(embedding_dimension,embedding_dimension),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_output2=nn.Linear(embedding_dimension,2)\n",
        "        \n",
        "        self.rgcn=RGCNConv(embedding_dimension,embedding_dimension,num_relations=2)\n",
        "        \n",
        "    def forward(self,des,tweet,numerical_properties,categorical_properties,edge_index,edge_type):\n",
        "        c=self.linear_relu_categorical_properties(categorical_properties)\n",
        "        x=c\n",
        "        \n",
        "        x=self.linear_relu_input(x)\n",
        "        x=self.rgcn(x,edge_index,edge_type)\n",
        "        x=F.dropout(x,p=self.dropout,training=self.training)\n",
        "        x=self.rgcn(x,edge_index,edge_type)\n",
        "        x=self.linear_relu_output1(x)\n",
        "        x=self.linear_output2(x)\n",
        "            \n",
        "        return x"
      ],
      "metadata": {
        "id": "TxWCJc43mYWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RGCN5(numerical_properties_size=6,categorical_properties_size=3,embedding_dimension=128).to(device)\n",
        "loss=nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train(epoch)\n",
        "    \n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KkCOyM7mZqg",
        "outputId": "e72e8db1-319c-4346-924e-5e98b53b97ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 loss_train: 1.0062 acc_train: 0.5060 acc_val: 0.5061\n",
            "Epoch: 0002 loss_train: 0.6156 acc_train: 0.6660 acc_val: 0.6812\n",
            "Epoch: 0003 loss_train: 0.5629 acc_train: 0.7554 acc_val: 0.7391\n",
            "Epoch: 0004 loss_train: 0.5393 acc_train: 0.7868 acc_val: 0.7729\n",
            "Epoch: 0005 loss_train: 0.5078 acc_train: 0.8016 acc_val: 0.7801\n",
            "Epoch: 0006 loss_train: 0.4741 acc_train: 0.7995 acc_val: 0.7839\n",
            "Epoch: 0007 loss_train: 0.4705 acc_train: 0.7855 acc_val: 0.7827\n",
            "Epoch: 0008 loss_train: 0.4785 acc_train: 0.7536 acc_val: 0.7366\n",
            "Epoch: 0009 loss_train: 0.4912 acc_train: 0.7397 acc_val: 0.7387\n",
            "Epoch: 0010 loss_train: 0.4729 acc_train: 0.7617 acc_val: 0.7459\n",
            "Epoch: 0011 loss_train: 0.4583 acc_train: 0.7917 acc_val: 0.7763\n",
            "Epoch: 0012 loss_train: 0.4513 acc_train: 0.8029 acc_val: 0.7869\n",
            "Epoch: 0013 loss_train: 0.4529 acc_train: 0.8033 acc_val: 0.7945\n",
            "Epoch: 0014 loss_train: 0.4475 acc_train: 0.8060 acc_val: 0.7966\n",
            "Epoch: 0015 loss_train: 0.4502 acc_train: 0.8027 acc_val: 0.7962\n",
            "Epoch: 0016 loss_train: 0.4527 acc_train: 0.7991 acc_val: 0.7869\n",
            "Epoch: 0017 loss_train: 0.4524 acc_train: 0.7990 acc_val: 0.7818\n",
            "Epoch: 0018 loss_train: 0.4436 acc_train: 0.7989 acc_val: 0.7890\n",
            "Epoch: 0019 loss_train: 0.4406 acc_train: 0.8000 acc_val: 0.7899\n",
            "Epoch: 0020 loss_train: 0.4373 acc_train: 0.8016 acc_val: 0.7924\n",
            "Epoch: 0021 loss_train: 0.4375 acc_train: 0.8010 acc_val: 0.7928\n",
            "Epoch: 0022 loss_train: 0.4384 acc_train: 0.8047 acc_val: 0.7877\n",
            "Epoch: 0023 loss_train: 0.4360 acc_train: 0.8058 acc_val: 0.7907\n",
            "Epoch: 0024 loss_train: 0.4359 acc_train: 0.8053 acc_val: 0.7937\n",
            "Epoch: 0025 loss_train: 0.4368 acc_train: 0.8071 acc_val: 0.7886\n",
            "Epoch: 0026 loss_train: 0.4357 acc_train: 0.8080 acc_val: 0.7928\n",
            "Epoch: 0027 loss_train: 0.4329 acc_train: 0.8088 acc_val: 0.7962\n",
            "Epoch: 0028 loss_train: 0.4328 acc_train: 0.8078 acc_val: 0.7958\n",
            "Epoch: 0029 loss_train: 0.4356 acc_train: 0.8070 acc_val: 0.7915\n",
            "Epoch: 0030 loss_train: 0.4330 acc_train: 0.8073 acc_val: 0.7915\n",
            "Epoch: 0031 loss_train: 0.4296 acc_train: 0.8077 acc_val: 0.7962\n",
            "Epoch: 0032 loss_train: 0.4319 acc_train: 0.8073 acc_val: 0.7962\n",
            "Epoch: 0033 loss_train: 0.4314 acc_train: 0.8086 acc_val: 0.7962\n",
            "Epoch: 0034 loss_train: 0.4304 acc_train: 0.8080 acc_val: 0.7958\n",
            "Epoch: 0035 loss_train: 0.4299 acc_train: 0.8080 acc_val: 0.7966\n",
            "Epoch: 0036 loss_train: 0.4330 acc_train: 0.8078 acc_val: 0.7953\n",
            "Epoch: 0037 loss_train: 0.4294 acc_train: 0.8086 acc_val: 0.7932\n",
            "Epoch: 0038 loss_train: 0.4272 acc_train: 0.8083 acc_val: 0.7958\n",
            "Epoch: 0039 loss_train: 0.4288 acc_train: 0.8077 acc_val: 0.7949\n",
            "Epoch: 0040 loss_train: 0.4273 acc_train: 0.8093 acc_val: 0.7966\n",
            "Epoch: 0041 loss_train: 0.4320 acc_train: 0.8072 acc_val: 0.7920\n",
            "Epoch: 0042 loss_train: 0.4308 acc_train: 0.8074 acc_val: 0.7932\n",
            "Epoch: 0043 loss_train: 0.4265 acc_train: 0.8093 acc_val: 0.7962\n",
            "Epoch: 0044 loss_train: 0.4271 acc_train: 0.8095 acc_val: 0.7949\n",
            "Epoch: 0045 loss_train: 0.4279 acc_train: 0.8101 acc_val: 0.7962\n",
            "Epoch: 0046 loss_train: 0.4262 acc_train: 0.8074 acc_val: 0.7958\n",
            "Epoch: 0047 loss_train: 0.4260 acc_train: 0.8085 acc_val: 0.7937\n",
            "Epoch: 0048 loss_train: 0.4270 acc_train: 0.8095 acc_val: 0.7949\n",
            "Epoch: 0049 loss_train: 0.4274 acc_train: 0.8082 acc_val: 0.7953\n",
            "Epoch: 0050 loss_train: 0.4253 acc_train: 0.8088 acc_val: 0.7958\n",
            "Epoch: 0051 loss_train: 0.4254 acc_train: 0.8095 acc_val: 0.7962\n",
            "Epoch: 0052 loss_train: 0.4261 acc_train: 0.8093 acc_val: 0.7949\n",
            "Epoch: 0053 loss_train: 0.4246 acc_train: 0.8088 acc_val: 0.7953\n",
            "Epoch: 0054 loss_train: 0.4250 acc_train: 0.8083 acc_val: 0.7949\n",
            "Epoch: 0055 loss_train: 0.4262 acc_train: 0.8088 acc_val: 0.7953\n",
            "Epoch: 0056 loss_train: 0.4243 acc_train: 0.8091 acc_val: 0.7953\n",
            "Epoch: 0057 loss_train: 0.4251 acc_train: 0.8089 acc_val: 0.7953\n",
            "Epoch: 0058 loss_train: 0.4233 acc_train: 0.8094 acc_val: 0.7949\n",
            "Epoch: 0059 loss_train: 0.4249 acc_train: 0.8099 acc_val: 0.7958\n",
            "Epoch: 0060 loss_train: 0.4251 acc_train: 0.8090 acc_val: 0.7949\n",
            "Epoch: 0061 loss_train: 0.4244 acc_train: 0.8097 acc_val: 0.7958\n",
            "Epoch: 0062 loss_train: 0.4259 acc_train: 0.8090 acc_val: 0.7958\n",
            "Epoch: 0063 loss_train: 0.4234 acc_train: 0.8094 acc_val: 0.7941\n",
            "Epoch: 0064 loss_train: 0.4226 acc_train: 0.8097 acc_val: 0.7949\n",
            "Epoch: 0065 loss_train: 0.4229 acc_train: 0.8093 acc_val: 0.7958\n",
            "Epoch: 0066 loss_train: 0.4236 acc_train: 0.8090 acc_val: 0.7945\n",
            "Epoch: 0067 loss_train: 0.4226 acc_train: 0.8100 acc_val: 0.7962\n",
            "Epoch: 0068 loss_train: 0.4227 acc_train: 0.8094 acc_val: 0.7941\n",
            "Epoch: 0069 loss_train: 0.4238 acc_train: 0.8094 acc_val: 0.7953\n",
            "Epoch: 0070 loss_train: 0.4252 acc_train: 0.8089 acc_val: 0.7949\n",
            "Epoch: 0071 loss_train: 0.4221 acc_train: 0.8100 acc_val: 0.7941\n",
            "Epoch: 0072 loss_train: 0.4223 acc_train: 0.8089 acc_val: 0.7953\n",
            "Epoch: 0073 loss_train: 0.4220 acc_train: 0.8101 acc_val: 0.7958\n",
            "Epoch: 0074 loss_train: 0.4214 acc_train: 0.8097 acc_val: 0.7945\n",
            "Epoch: 0075 loss_train: 0.4231 acc_train: 0.8102 acc_val: 0.7937\n",
            "Epoch: 0076 loss_train: 0.4242 acc_train: 0.8083 acc_val: 0.7953\n",
            "Epoch: 0077 loss_train: 0.4221 acc_train: 0.8097 acc_val: 0.7949\n",
            "Epoch: 0078 loss_train: 0.4221 acc_train: 0.8093 acc_val: 0.7966\n",
            "Epoch: 0079 loss_train: 0.4226 acc_train: 0.8091 acc_val: 0.7941\n",
            "Epoch: 0080 loss_train: 0.4225 acc_train: 0.8096 acc_val: 0.7958\n",
            "Epoch: 0081 loss_train: 0.4230 acc_train: 0.8089 acc_val: 0.7941\n",
            "Epoch: 0082 loss_train: 0.4232 acc_train: 0.8091 acc_val: 0.7958\n",
            "Epoch: 0083 loss_train: 0.4237 acc_train: 0.8100 acc_val: 0.7953\n",
            "Epoch: 0084 loss_train: 0.4230 acc_train: 0.8094 acc_val: 0.7958\n",
            "Epoch: 0085 loss_train: 0.4227 acc_train: 0.8099 acc_val: 0.7949\n",
            "Epoch: 0086 loss_train: 0.4213 acc_train: 0.8097 acc_val: 0.7949\n",
            "Epoch: 0087 loss_train: 0.4215 acc_train: 0.8096 acc_val: 0.7949\n",
            "Epoch: 0088 loss_train: 0.4202 acc_train: 0.8090 acc_val: 0.7949\n",
            "Epoch: 0089 loss_train: 0.4216 acc_train: 0.8099 acc_val: 0.7966\n",
            "Epoch: 0090 loss_train: 0.4213 acc_train: 0.8090 acc_val: 0.7953\n",
            "Epoch: 0091 loss_train: 0.4210 acc_train: 0.8099 acc_val: 0.7962\n",
            "Epoch: 0092 loss_train: 0.4212 acc_train: 0.8100 acc_val: 0.7941\n",
            "Epoch: 0093 loss_train: 0.4216 acc_train: 0.8096 acc_val: 0.7958\n",
            "Epoch: 0094 loss_train: 0.4230 acc_train: 0.8090 acc_val: 0.7949\n",
            "Epoch: 0095 loss_train: 0.4216 acc_train: 0.8095 acc_val: 0.7958\n",
            "Epoch: 0096 loss_train: 0.4208 acc_train: 0.8097 acc_val: 0.7941\n",
            "Epoch: 0097 loss_train: 0.4214 acc_train: 0.8105 acc_val: 0.7953\n",
            "Epoch: 0098 loss_train: 0.4188 acc_train: 0.8102 acc_val: 0.7966\n",
            "Epoch: 0099 loss_train: 0.4218 acc_train: 0.8099 acc_val: 0.7949\n",
            "Epoch: 0100 loss_train: 0.4214 acc_train: 0.8088 acc_val: 0.7928\n",
            "Test set results: test_loss= 0.4055 test_accuracy= 0.8157 f1_score= 0.8541 mcc= 0.6663\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.8157, dtype=torch.float64),\n",
              " tensor(0.4055, grad_fn=<NllLossBackward0>),\n",
              " <function sklearn.metrics._classification.f1_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')>)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RGCN6 - Using Description Feature and Tweets Feature"
      ],
      "metadata": {
        "id": "vokjSCOYen0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RGCN6(nn.Module):\n",
        "    def __init__(self,description_size=768,tweet_size=768,numerical_properties_size=6,categorical_properties_size=3,embedding_dimension=128,dropout=0.3):\n",
        "        super(RGCN6, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.linear_relu_description=nn.Sequential(\n",
        "            nn.Linear(description_size,int(embedding_dimension/2)),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "\n",
        "        self.linear_relu_tweet=nn.Sequential(\n",
        "            nn.Linear(tweet_size,int(embedding_dimension/2)),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_relu_input=nn.Sequential(\n",
        "            nn.Linear(embedding_dimension,embedding_dimension),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_relu_output1=nn.Sequential(\n",
        "            nn.Linear(embedding_dimension,embedding_dimension),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_output2=nn.Linear(embedding_dimension,2)\n",
        "        \n",
        "        self.rgcn=RGCNConv(embedding_dimension,embedding_dimension,num_relations=2)\n",
        "        \n",
        "    def forward(self,des,tweet,numerical_properties,categorical_properties,edge_index,edge_type):\n",
        "        d=self.linear_relu_description(des)\n",
        "        t=self.linear_relu_tweet(tweet)\n",
        "        x=torch.cat((d,t),dim=1)\n",
        "        \n",
        "        x=self.linear_relu_input(x)\n",
        "        x=self.rgcn(x,edge_index,edge_type)\n",
        "        x=F.dropout(x,p=self.dropout,training=self.training)\n",
        "        x=self.rgcn(x,edge_index,edge_type)\n",
        "        x=self.linear_relu_output1(x)\n",
        "        x=self.linear_output2(x)\n",
        "            \n",
        "        return x"
      ],
      "metadata": {
        "id": "Uw8XlPS3qzit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RGCN6(numerical_properties_size=6,categorical_properties_size=3,embedding_dimension=128).to(device)\n",
        "loss=nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train(epoch)\n",
        "    \n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQTXSHEXqzoM",
        "outputId": "1bf4b20d-03f0-4258-8e9c-e05c4f9689ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 loss_train: 1.1916 acc_train: 0.4121 acc_val: 0.4055\n",
            "Epoch: 0002 loss_train: 0.8418 acc_train: 0.6200 acc_val: 0.6156\n",
            "Epoch: 0003 loss_train: 0.8691 acc_train: 0.6316 acc_val: 0.6414\n",
            "Epoch: 0004 loss_train: 0.7913 acc_train: 0.6282 acc_val: 0.6440\n",
            "Epoch: 0005 loss_train: 0.7190 acc_train: 0.6139 acc_val: 0.6237\n",
            "Epoch: 0006 loss_train: 0.6599 acc_train: 0.6285 acc_val: 0.6342\n",
            "Epoch: 0007 loss_train: 0.6603 acc_train: 0.6098 acc_val: 0.6186\n",
            "Epoch: 0008 loss_train: 0.6916 acc_train: 0.5710 acc_val: 0.5911\n",
            "Epoch: 0009 loss_train: 0.6794 acc_train: 0.5840 acc_val: 0.5928\n",
            "Epoch: 0010 loss_train: 0.6522 acc_train: 0.6219 acc_val: 0.6431\n",
            "Epoch: 0011 loss_train: 0.6307 acc_train: 0.6596 acc_val: 0.6778\n",
            "Epoch: 0012 loss_train: 0.6238 acc_train: 0.6648 acc_val: 0.6744\n",
            "Epoch: 0013 loss_train: 0.6212 acc_train: 0.6684 acc_val: 0.6753\n",
            "Epoch: 0014 loss_train: 0.6202 acc_train: 0.6756 acc_val: 0.6757\n",
            "Epoch: 0015 loss_train: 0.6184 acc_train: 0.6747 acc_val: 0.6850\n",
            "Epoch: 0016 loss_train: 0.6148 acc_train: 0.6808 acc_val: 0.6820\n",
            "Epoch: 0017 loss_train: 0.6084 acc_train: 0.6800 acc_val: 0.6930\n",
            "Epoch: 0018 loss_train: 0.6059 acc_train: 0.6784 acc_val: 0.6841\n",
            "Epoch: 0019 loss_train: 0.5989 acc_train: 0.6864 acc_val: 0.6922\n",
            "Epoch: 0020 loss_train: 0.5949 acc_train: 0.6877 acc_val: 0.6951\n",
            "Epoch: 0021 loss_train: 0.5937 acc_train: 0.6953 acc_val: 0.7027\n",
            "Epoch: 0022 loss_train: 0.5870 acc_train: 0.7007 acc_val: 0.6998\n",
            "Epoch: 0023 loss_train: 0.5854 acc_train: 0.7023 acc_val: 0.7027\n",
            "Epoch: 0024 loss_train: 0.5839 acc_train: 0.7054 acc_val: 0.7061\n",
            "Epoch: 0025 loss_train: 0.5770 acc_train: 0.7150 acc_val: 0.7091\n",
            "Epoch: 0026 loss_train: 0.5734 acc_train: 0.7115 acc_val: 0.7129\n",
            "Epoch: 0027 loss_train: 0.5700 acc_train: 0.7127 acc_val: 0.7285\n",
            "Epoch: 0028 loss_train: 0.5630 acc_train: 0.7238 acc_val: 0.7239\n",
            "Epoch: 0029 loss_train: 0.5577 acc_train: 0.7218 acc_val: 0.7226\n",
            "Epoch: 0030 loss_train: 0.5552 acc_train: 0.7240 acc_val: 0.7256\n",
            "Epoch: 0031 loss_train: 0.5533 acc_train: 0.7258 acc_val: 0.7311\n",
            "Epoch: 0032 loss_train: 0.5484 acc_train: 0.7276 acc_val: 0.7323\n",
            "Epoch: 0033 loss_train: 0.5457 acc_train: 0.7316 acc_val: 0.7362\n",
            "Epoch: 0034 loss_train: 0.5396 acc_train: 0.7359 acc_val: 0.7362\n",
            "Epoch: 0035 loss_train: 0.5392 acc_train: 0.7358 acc_val: 0.7467\n",
            "Epoch: 0036 loss_train: 0.5329 acc_train: 0.7398 acc_val: 0.7484\n",
            "Epoch: 0037 loss_train: 0.5309 acc_train: 0.7432 acc_val: 0.7455\n",
            "Epoch: 0038 loss_train: 0.5311 acc_train: 0.7414 acc_val: 0.7501\n",
            "Epoch: 0039 loss_train: 0.5253 acc_train: 0.7479 acc_val: 0.7429\n",
            "Epoch: 0040 loss_train: 0.5246 acc_train: 0.7532 acc_val: 0.7488\n",
            "Epoch: 0041 loss_train: 0.5205 acc_train: 0.7493 acc_val: 0.7552\n",
            "Epoch: 0042 loss_train: 0.5169 acc_train: 0.7520 acc_val: 0.7488\n",
            "Epoch: 0043 loss_train: 0.5112 acc_train: 0.7559 acc_val: 0.7581\n",
            "Epoch: 0044 loss_train: 0.5121 acc_train: 0.7567 acc_val: 0.7586\n",
            "Epoch: 0045 loss_train: 0.5038 acc_train: 0.7614 acc_val: 0.7531\n",
            "Epoch: 0046 loss_train: 0.5012 acc_train: 0.7621 acc_val: 0.7603\n",
            "Epoch: 0047 loss_train: 0.4978 acc_train: 0.7656 acc_val: 0.7641\n",
            "Epoch: 0048 loss_train: 0.4954 acc_train: 0.7638 acc_val: 0.7691\n",
            "Epoch: 0049 loss_train: 0.4913 acc_train: 0.7707 acc_val: 0.7691\n",
            "Epoch: 0050 loss_train: 0.4878 acc_train: 0.7700 acc_val: 0.7691\n",
            "Epoch: 0051 loss_train: 0.4843 acc_train: 0.7801 acc_val: 0.7738\n",
            "Epoch: 0052 loss_train: 0.4822 acc_train: 0.7760 acc_val: 0.7767\n",
            "Epoch: 0053 loss_train: 0.4768 acc_train: 0.7791 acc_val: 0.7797\n",
            "Epoch: 0054 loss_train: 0.4748 acc_train: 0.7792 acc_val: 0.7856\n",
            "Epoch: 0055 loss_train: 0.4683 acc_train: 0.7870 acc_val: 0.7797\n",
            "Epoch: 0056 loss_train: 0.4685 acc_train: 0.7861 acc_val: 0.7822\n",
            "Epoch: 0057 loss_train: 0.4631 acc_train: 0.7861 acc_val: 0.7869\n",
            "Epoch: 0058 loss_train: 0.4605 acc_train: 0.7874 acc_val: 0.7835\n",
            "Epoch: 0059 loss_train: 0.4576 acc_train: 0.7898 acc_val: 0.7860\n",
            "Epoch: 0060 loss_train: 0.4538 acc_train: 0.7914 acc_val: 0.7860\n",
            "Epoch: 0061 loss_train: 0.4526 acc_train: 0.7903 acc_val: 0.7899\n",
            "Epoch: 0062 loss_train: 0.4476 acc_train: 0.7937 acc_val: 0.7937\n",
            "Epoch: 0063 loss_train: 0.4434 acc_train: 0.7977 acc_val: 0.7839\n",
            "Epoch: 0064 loss_train: 0.4400 acc_train: 0.8012 acc_val: 0.7949\n",
            "Epoch: 0065 loss_train: 0.4391 acc_train: 0.8016 acc_val: 0.7848\n",
            "Epoch: 0066 loss_train: 0.4352 acc_train: 0.8025 acc_val: 0.7920\n",
            "Epoch: 0067 loss_train: 0.4333 acc_train: 0.8004 acc_val: 0.7886\n",
            "Epoch: 0068 loss_train: 0.4273 acc_train: 0.8045 acc_val: 0.7937\n",
            "Epoch: 0069 loss_train: 0.4264 acc_train: 0.8067 acc_val: 0.7873\n",
            "Epoch: 0070 loss_train: 0.4247 acc_train: 0.8060 acc_val: 0.7979\n",
            "Epoch: 0071 loss_train: 0.4215 acc_train: 0.8094 acc_val: 0.7903\n",
            "Epoch: 0072 loss_train: 0.4170 acc_train: 0.8112 acc_val: 0.7894\n",
            "Epoch: 0073 loss_train: 0.4166 acc_train: 0.8129 acc_val: 0.7970\n",
            "Epoch: 0074 loss_train: 0.4118 acc_train: 0.8137 acc_val: 0.7890\n",
            "Epoch: 0075 loss_train: 0.4083 acc_train: 0.8154 acc_val: 0.7911\n",
            "Epoch: 0076 loss_train: 0.4102 acc_train: 0.8147 acc_val: 0.7924\n",
            "Epoch: 0077 loss_train: 0.4081 acc_train: 0.8128 acc_val: 0.7920\n",
            "Epoch: 0078 loss_train: 0.4041 acc_train: 0.8138 acc_val: 0.7873\n",
            "Epoch: 0079 loss_train: 0.4011 acc_train: 0.8218 acc_val: 0.7911\n",
            "Epoch: 0080 loss_train: 0.3999 acc_train: 0.8199 acc_val: 0.7966\n",
            "Epoch: 0081 loss_train: 0.3971 acc_train: 0.8215 acc_val: 0.7915\n",
            "Epoch: 0082 loss_train: 0.3925 acc_train: 0.8239 acc_val: 0.7894\n",
            "Epoch: 0083 loss_train: 0.3916 acc_train: 0.8245 acc_val: 0.7962\n",
            "Epoch: 0084 loss_train: 0.3884 acc_train: 0.8281 acc_val: 0.7856\n",
            "Epoch: 0085 loss_train: 0.3852 acc_train: 0.8266 acc_val: 0.7877\n",
            "Epoch: 0086 loss_train: 0.3813 acc_train: 0.8321 acc_val: 0.7886\n",
            "Epoch: 0087 loss_train: 0.3801 acc_train: 0.8331 acc_val: 0.7937\n",
            "Epoch: 0088 loss_train: 0.3760 acc_train: 0.8329 acc_val: 0.7911\n",
            "Epoch: 0089 loss_train: 0.3752 acc_train: 0.8384 acc_val: 0.7827\n",
            "Epoch: 0090 loss_train: 0.3692 acc_train: 0.8387 acc_val: 0.7877\n",
            "Epoch: 0091 loss_train: 0.3711 acc_train: 0.8366 acc_val: 0.7848\n",
            "Epoch: 0092 loss_train: 0.3710 acc_train: 0.8391 acc_val: 0.7839\n",
            "Epoch: 0093 loss_train: 0.3654 acc_train: 0.8388 acc_val: 0.7932\n",
            "Epoch: 0094 loss_train: 0.3636 acc_train: 0.8386 acc_val: 0.7903\n",
            "Epoch: 0095 loss_train: 0.3561 acc_train: 0.8488 acc_val: 0.7848\n",
            "Epoch: 0096 loss_train: 0.3539 acc_train: 0.8450 acc_val: 0.7856\n",
            "Epoch: 0097 loss_train: 0.3544 acc_train: 0.8456 acc_val: 0.7869\n",
            "Epoch: 0098 loss_train: 0.3511 acc_train: 0.8484 acc_val: 0.7877\n",
            "Epoch: 0099 loss_train: 0.3487 acc_train: 0.8504 acc_val: 0.7844\n",
            "Epoch: 0100 loss_train: 0.3403 acc_train: 0.8564 acc_val: 0.7886\n",
            "Test set results: test_loss= 0.5357 test_accuracy= 0.7675 f1_score= 0.7850 mcc= 0.5320\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.7675, dtype=torch.float64),\n",
              " tensor(0.5357, grad_fn=<NllLossBackward0>),\n",
              " <function sklearn.metrics._classification.f1_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')>)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RGCN7 - Using Numerical Properties feature and Categorical Properties feature"
      ],
      "metadata": {
        "id": "UzGUrIqneuLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RGCN7(nn.Module):\n",
        "    def __init__(self,description_size=768,tweet_size=768,numerical_properties_size=6,categorical_properties_size=3,embedding_dimension=128,dropout=0.3):\n",
        "        super(RGCN7, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.linear_relu_numerical_properties=nn.Sequential(\n",
        "            nn.Linear(numerical_properties_size,int(embedding_dimension/2)),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_relu_categorical_properties=nn.Sequential(\n",
        "            nn.Linear(categorical_properties_size,int(embedding_dimension/2)),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_relu_input=nn.Sequential(\n",
        "            nn.Linear(embedding_dimension,embedding_dimension),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_relu_output1=nn.Sequential(\n",
        "            nn.Linear(embedding_dimension,embedding_dimension),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_output2=nn.Linear(embedding_dimension,2)\n",
        "        \n",
        "        self.rgcn=RGCNConv(embedding_dimension,embedding_dimension,num_relations=2)\n",
        "        \n",
        "    def forward(self,des,tweet,numerical_properties,categorical_properties,edge_index,edge_type):\n",
        "        n=self.linear_relu_numerical_properties(numerical_properties)\n",
        "        c=self.linear_relu_categorical_properties(categorical_properties)\n",
        "        x=torch.cat((n,c),dim=1)\n",
        "        \n",
        "        x=self.linear_relu_input(x)\n",
        "        x=self.rgcn(x,edge_index,edge_type)\n",
        "        x=F.dropout(x,p=self.dropout,training=self.training)\n",
        "        x=self.rgcn(x,edge_index,edge_type)\n",
        "        x=self.linear_relu_output1(x)\n",
        "        x=self.linear_output2(x)\n",
        "            \n",
        "        return x"
      ],
      "metadata": {
        "id": "ZeC895KzrUN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RGCN7(numerical_properties_size=6,categorical_properties_size=3,embedding_dimension=128).to(device)\n",
        "loss=nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train(epoch)\n",
        "    \n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Yk312ItrUVr",
        "outputId": "16608512-6b1a-4154-953e-c3ef6c429c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 loss_train: 1.3501 acc_train: 0.5063 acc_val: 0.4918\n",
            "Epoch: 0002 loss_train: 0.8284 acc_train: 0.6371 acc_val: 0.6419\n",
            "Epoch: 0003 loss_train: 0.7536 acc_train: 0.6963 acc_val: 0.7074\n",
            "Epoch: 0004 loss_train: 0.7081 acc_train: 0.7254 acc_val: 0.7184\n",
            "Epoch: 0005 loss_train: 0.6519 acc_train: 0.7354 acc_val: 0.7294\n",
            "Epoch: 0006 loss_train: 0.6275 acc_train: 0.7211 acc_val: 0.7340\n",
            "Epoch: 0007 loss_train: 0.6255 acc_train: 0.7230 acc_val: 0.7235\n",
            "Epoch: 0008 loss_train: 0.5828 acc_train: 0.7287 acc_val: 0.7290\n",
            "Epoch: 0009 loss_train: 0.5599 acc_train: 0.7583 acc_val: 0.7607\n",
            "Epoch: 0010 loss_train: 0.5327 acc_train: 0.7768 acc_val: 0.7632\n",
            "Epoch: 0011 loss_train: 0.5181 acc_train: 0.7853 acc_val: 0.7712\n",
            "Epoch: 0012 loss_train: 0.5293 acc_train: 0.7838 acc_val: 0.7717\n",
            "Epoch: 0013 loss_train: 0.5102 acc_train: 0.7900 acc_val: 0.7721\n",
            "Epoch: 0014 loss_train: 0.4968 acc_train: 0.7760 acc_val: 0.7755\n",
            "Epoch: 0015 loss_train: 0.4838 acc_train: 0.7723 acc_val: 0.7683\n",
            "Epoch: 0016 loss_train: 0.4994 acc_train: 0.7752 acc_val: 0.7552\n",
            "Epoch: 0017 loss_train: 0.4771 acc_train: 0.7747 acc_val: 0.7712\n",
            "Epoch: 0018 loss_train: 0.4763 acc_train: 0.7876 acc_val: 0.7780\n",
            "Epoch: 0019 loss_train: 0.4830 acc_train: 0.7888 acc_val: 0.7801\n",
            "Epoch: 0020 loss_train: 0.4738 acc_train: 0.7958 acc_val: 0.7890\n",
            "Epoch: 0021 loss_train: 0.4827 acc_train: 0.8015 acc_val: 0.7869\n",
            "Epoch: 0022 loss_train: 0.4672 acc_train: 0.8001 acc_val: 0.7848\n",
            "Epoch: 0023 loss_train: 0.4640 acc_train: 0.7990 acc_val: 0.7852\n",
            "Epoch: 0024 loss_train: 0.4581 acc_train: 0.7985 acc_val: 0.7822\n",
            "Epoch: 0025 loss_train: 0.4555 acc_train: 0.7928 acc_val: 0.7763\n",
            "Epoch: 0026 loss_train: 0.4543 acc_train: 0.7946 acc_val: 0.7848\n",
            "Epoch: 0027 loss_train: 0.4526 acc_train: 0.7928 acc_val: 0.7831\n",
            "Epoch: 0028 loss_train: 0.4511 acc_train: 0.7954 acc_val: 0.7860\n",
            "Epoch: 0029 loss_train: 0.4542 acc_train: 0.7980 acc_val: 0.7844\n",
            "Epoch: 0030 loss_train: 0.4550 acc_train: 0.8003 acc_val: 0.7894\n",
            "Epoch: 0031 loss_train: 0.4345 acc_train: 0.8048 acc_val: 0.7970\n",
            "Epoch: 0032 loss_train: 0.4423 acc_train: 0.8054 acc_val: 0.7924\n",
            "Epoch: 0033 loss_train: 0.4388 acc_train: 0.8061 acc_val: 0.7958\n",
            "Epoch: 0034 loss_train: 0.4388 acc_train: 0.8059 acc_val: 0.7970\n",
            "Epoch: 0035 loss_train: 0.4367 acc_train: 0.8053 acc_val: 0.7911\n",
            "Epoch: 0036 loss_train: 0.4311 acc_train: 0.8053 acc_val: 0.7894\n",
            "Epoch: 0037 loss_train: 0.4347 acc_train: 0.8009 acc_val: 0.7915\n",
            "Epoch: 0038 loss_train: 0.4326 acc_train: 0.8043 acc_val: 0.7869\n",
            "Epoch: 0039 loss_train: 0.4267 acc_train: 0.8061 acc_val: 0.7907\n",
            "Epoch: 0040 loss_train: 0.4253 acc_train: 0.8055 acc_val: 0.7924\n",
            "Epoch: 0041 loss_train: 0.4287 acc_train: 0.8059 acc_val: 0.7949\n",
            "Epoch: 0042 loss_train: 0.4323 acc_train: 0.8060 acc_val: 0.7907\n",
            "Epoch: 0043 loss_train: 0.4204 acc_train: 0.8090 acc_val: 0.7953\n",
            "Epoch: 0044 loss_train: 0.4244 acc_train: 0.8066 acc_val: 0.7924\n",
            "Epoch: 0045 loss_train: 0.4212 acc_train: 0.8086 acc_val: 0.7924\n",
            "Epoch: 0046 loss_train: 0.4255 acc_train: 0.8061 acc_val: 0.7924\n",
            "Epoch: 0047 loss_train: 0.4256 acc_train: 0.8064 acc_val: 0.7894\n",
            "Epoch: 0048 loss_train: 0.4214 acc_train: 0.8072 acc_val: 0.7941\n",
            "Epoch: 0049 loss_train: 0.4214 acc_train: 0.8058 acc_val: 0.7941\n",
            "Epoch: 0050 loss_train: 0.4176 acc_train: 0.8084 acc_val: 0.7915\n",
            "Epoch: 0051 loss_train: 0.4196 acc_train: 0.8068 acc_val: 0.7907\n",
            "Epoch: 0052 loss_train: 0.4233 acc_train: 0.8077 acc_val: 0.7899\n",
            "Epoch: 0053 loss_train: 0.4160 acc_train: 0.8101 acc_val: 0.7970\n",
            "Epoch: 0054 loss_train: 0.4185 acc_train: 0.8077 acc_val: 0.7953\n",
            "Epoch: 0055 loss_train: 0.4249 acc_train: 0.8083 acc_val: 0.7953\n",
            "Epoch: 0056 loss_train: 0.4131 acc_train: 0.8112 acc_val: 0.7945\n",
            "Epoch: 0057 loss_train: 0.4146 acc_train: 0.8123 acc_val: 0.7945\n",
            "Epoch: 0058 loss_train: 0.4203 acc_train: 0.8061 acc_val: 0.7860\n",
            "Epoch: 0059 loss_train: 0.4156 acc_train: 0.8086 acc_val: 0.7894\n",
            "Epoch: 0060 loss_train: 0.4178 acc_train: 0.8099 acc_val: 0.7907\n",
            "Epoch: 0061 loss_train: 0.4126 acc_train: 0.8094 acc_val: 0.7882\n",
            "Epoch: 0062 loss_train: 0.4124 acc_train: 0.8100 acc_val: 0.7945\n",
            "Epoch: 0063 loss_train: 0.4096 acc_train: 0.8100 acc_val: 0.7941\n",
            "Epoch: 0064 loss_train: 0.4110 acc_train: 0.8105 acc_val: 0.7945\n",
            "Epoch: 0065 loss_train: 0.4101 acc_train: 0.8105 acc_val: 0.7941\n",
            "Epoch: 0066 loss_train: 0.4066 acc_train: 0.8123 acc_val: 0.7979\n",
            "Epoch: 0067 loss_train: 0.4080 acc_train: 0.8106 acc_val: 0.7962\n",
            "Epoch: 0068 loss_train: 0.4059 acc_train: 0.8126 acc_val: 0.7958\n",
            "Epoch: 0069 loss_train: 0.4122 acc_train: 0.8113 acc_val: 0.7890\n",
            "Epoch: 0070 loss_train: 0.4152 acc_train: 0.8107 acc_val: 0.7924\n",
            "Epoch: 0071 loss_train: 0.4096 acc_train: 0.8088 acc_val: 0.7932\n",
            "Epoch: 0072 loss_train: 0.4085 acc_train: 0.8113 acc_val: 0.7877\n",
            "Epoch: 0073 loss_train: 0.4073 acc_train: 0.8103 acc_val: 0.7979\n",
            "Epoch: 0074 loss_train: 0.4044 acc_train: 0.8118 acc_val: 0.7882\n",
            "Epoch: 0075 loss_train: 0.4044 acc_train: 0.8135 acc_val: 0.7983\n",
            "Epoch: 0076 loss_train: 0.4021 acc_train: 0.8143 acc_val: 0.7970\n",
            "Epoch: 0077 loss_train: 0.4029 acc_train: 0.8165 acc_val: 0.7932\n",
            "Epoch: 0078 loss_train: 0.4042 acc_train: 0.8130 acc_val: 0.7920\n",
            "Epoch: 0079 loss_train: 0.4058 acc_train: 0.8097 acc_val: 0.7924\n",
            "Epoch: 0080 loss_train: 0.4045 acc_train: 0.8148 acc_val: 0.7932\n",
            "Epoch: 0081 loss_train: 0.4070 acc_train: 0.8117 acc_val: 0.7958\n",
            "Epoch: 0082 loss_train: 0.4035 acc_train: 0.8120 acc_val: 0.7899\n",
            "Epoch: 0083 loss_train: 0.4012 acc_train: 0.8163 acc_val: 0.7958\n",
            "Epoch: 0084 loss_train: 0.4031 acc_train: 0.8117 acc_val: 0.7987\n",
            "Epoch: 0085 loss_train: 0.4034 acc_train: 0.8138 acc_val: 0.7958\n",
            "Epoch: 0086 loss_train: 0.3976 acc_train: 0.8134 acc_val: 0.7949\n",
            "Epoch: 0087 loss_train: 0.4016 acc_train: 0.8124 acc_val: 0.7958\n",
            "Epoch: 0088 loss_train: 0.3987 acc_train: 0.8126 acc_val: 0.7941\n",
            "Epoch: 0089 loss_train: 0.4012 acc_train: 0.8140 acc_val: 0.7911\n",
            "Epoch: 0090 loss_train: 0.3976 acc_train: 0.8170 acc_val: 0.7966\n",
            "Epoch: 0091 loss_train: 0.3993 acc_train: 0.8163 acc_val: 0.7915\n",
            "Epoch: 0092 loss_train: 0.4012 acc_train: 0.8117 acc_val: 0.7970\n",
            "Epoch: 0093 loss_train: 0.3964 acc_train: 0.8140 acc_val: 0.7877\n",
            "Epoch: 0094 loss_train: 0.4009 acc_train: 0.8151 acc_val: 0.7894\n",
            "Epoch: 0095 loss_train: 0.3964 acc_train: 0.8161 acc_val: 0.7949\n",
            "Epoch: 0096 loss_train: 0.3943 acc_train: 0.8175 acc_val: 0.7920\n",
            "Epoch: 0097 loss_train: 0.3973 acc_train: 0.8141 acc_val: 0.7975\n",
            "Epoch: 0098 loss_train: 0.3952 acc_train: 0.8166 acc_val: 0.7920\n",
            "Epoch: 0099 loss_train: 0.3918 acc_train: 0.8177 acc_val: 0.7928\n",
            "Epoch: 0100 loss_train: 0.3990 acc_train: 0.8166 acc_val: 0.7928\n",
            "Test set results: test_loss= 0.4037 test_accuracy= 0.8183 f1_score= 0.8538 mcc= 0.6621\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.8183, dtype=torch.float64),\n",
              " tensor(0.4037, grad_fn=<NllLossBackward0>),\n",
              " <function sklearn.metrics._classification.f1_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')>)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GCN - Replacing RGCN with GCN"
      ],
      "metadata": {
        "id": "hscrnly4ew4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(nn.Module):\n",
        "    def __init__(self,description_size=768,tweet_size=768,numerical_properties_size=6,categorical_properties_size=3,embedding_dimension=128,dropout=0.3):\n",
        "        super(GCN, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.linear_relu_description=nn.Sequential(\n",
        "            nn.Linear(description_size,int(embedding_dimension/4)),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_relu_tweet=nn.Sequential(\n",
        "            nn.Linear(tweet_size,int(embedding_dimension/4)),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_relu_numerical_properties=nn.Sequential(\n",
        "            nn.Linear(numerical_properties_size,int(embedding_dimension/4)),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_relu_categorical_properties=nn.Sequential(\n",
        "            nn.Linear(categorical_properties_size,int(embedding_dimension/4)),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        \n",
        "        self.linear_relu_input=nn.Sequential(\n",
        "            nn.Linear(embedding_dimension,embedding_dimension),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_relu_output1=nn.Sequential(\n",
        "            nn.Linear(embedding_dimension,embedding_dimension),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_output2=nn.Linear(embedding_dimension,2)\n",
        "        \n",
        "        self.gcn1=GCNConv(embedding_dimension,embedding_dimension)\n",
        "        self.gcn2=GCNConv(embedding_dimension,embedding_dimension)\n",
        "        \n",
        "    def forward(self,des,tweet,numerical_properties,categorical_properties,edge_index,edge_type):\n",
        "        d=self.linear_relu_description(des)\n",
        "        t=self.linear_relu_tweet(tweet)\n",
        "        n=self.linear_relu_numerical_properties(numerical_properties)\n",
        "        c=self.linear_relu_categorical_properties(categorical_properties)\n",
        "        x=torch.cat((d,t,n,c),dim=1)\n",
        "        \n",
        "        x=self.linear_relu_input(x)\n",
        "        x=self.gcn1(x,edge_index)\n",
        "        x=F.dropout(x,p=self.dropout,training=self.training)\n",
        "        x=self.gcn2(x,edge_index)\n",
        "        x=self.linear_relu_output1(x)\n",
        "        x=self.linear_output2(x)\n",
        "            \n",
        "        return x"
      ],
      "metadata": {
        "id": "fx7FouvxruUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCN(numerical_properties_size=6,categorical_properties_size=3,embedding_dimension=128).to(device)\n",
        "loss=nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train(epoch)\n",
        "    \n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAyrJ0l9rucA",
        "outputId": "c3a6c410-dc77-42e0-a804-e96c58761d5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 loss_train: 0.7143 acc_train: 0.5197 acc_val: 0.5277\n",
            "Epoch: 0002 loss_train: 0.7929 acc_train: 0.5627 acc_val: 0.5510\n",
            "Epoch: 0003 loss_train: 0.6672 acc_train: 0.5843 acc_val: 0.5848\n",
            "Epoch: 0004 loss_train: 0.7216 acc_train: 0.4928 acc_val: 0.5002\n",
            "Epoch: 0005 loss_train: 0.6859 acc_train: 0.5244 acc_val: 0.5264\n",
            "Epoch: 0006 loss_train: 0.6463 acc_train: 0.6325 acc_val: 0.6317\n",
            "Epoch: 0007 loss_train: 0.6594 acc_train: 0.6123 acc_val: 0.6030\n",
            "Epoch: 0008 loss_train: 0.6653 acc_train: 0.6064 acc_val: 0.5924\n",
            "Epoch: 0009 loss_train: 0.6436 acc_train: 0.6434 acc_val: 0.6288\n",
            "Epoch: 0010 loss_train: 0.6268 acc_train: 0.6647 acc_val: 0.6638\n",
            "Epoch: 0011 loss_train: 0.6283 acc_train: 0.6406 acc_val: 0.6368\n",
            "Epoch: 0012 loss_train: 0.6374 acc_train: 0.6219 acc_val: 0.6279\n",
            "Epoch: 0013 loss_train: 0.6287 acc_train: 0.6359 acc_val: 0.6359\n",
            "Epoch: 0014 loss_train: 0.6208 acc_train: 0.6544 acc_val: 0.6668\n",
            "Epoch: 0015 loss_train: 0.6121 acc_train: 0.6781 acc_val: 0.6753\n",
            "Epoch: 0016 loss_train: 0.6125 acc_train: 0.6785 acc_val: 0.6698\n",
            "Epoch: 0017 loss_train: 0.6099 acc_train: 0.6766 acc_val: 0.6719\n",
            "Epoch: 0018 loss_train: 0.6030 acc_train: 0.6817 acc_val: 0.6782\n",
            "Epoch: 0019 loss_train: 0.5981 acc_train: 0.6895 acc_val: 0.6846\n",
            "Epoch: 0020 loss_train: 0.5928 acc_train: 0.6898 acc_val: 0.6930\n",
            "Epoch: 0021 loss_train: 0.5948 acc_train: 0.6874 acc_val: 0.6863\n",
            "Epoch: 0022 loss_train: 0.5873 acc_train: 0.6920 acc_val: 0.6913\n",
            "Epoch: 0023 loss_train: 0.5784 acc_train: 0.6991 acc_val: 0.6951\n",
            "Epoch: 0024 loss_train: 0.5798 acc_train: 0.6969 acc_val: 0.6926\n",
            "Epoch: 0025 loss_train: 0.5798 acc_train: 0.6988 acc_val: 0.6947\n",
            "Epoch: 0026 loss_train: 0.5737 acc_train: 0.7052 acc_val: 0.7053\n",
            "Epoch: 0027 loss_train: 0.5676 acc_train: 0.7016 acc_val: 0.6939\n",
            "Epoch: 0028 loss_train: 0.5638 acc_train: 0.7057 acc_val: 0.6977\n",
            "Epoch: 0029 loss_train: 0.5606 acc_train: 0.7138 acc_val: 0.6994\n",
            "Epoch: 0030 loss_train: 0.5603 acc_train: 0.7129 acc_val: 0.7082\n",
            "Epoch: 0031 loss_train: 0.5575 acc_train: 0.7151 acc_val: 0.7011\n",
            "Epoch: 0032 loss_train: 0.5533 acc_train: 0.7184 acc_val: 0.7095\n",
            "Epoch: 0033 loss_train: 0.5540 acc_train: 0.7147 acc_val: 0.7125\n",
            "Epoch: 0034 loss_train: 0.5477 acc_train: 0.7149 acc_val: 0.7104\n",
            "Epoch: 0035 loss_train: 0.5435 acc_train: 0.7229 acc_val: 0.7243\n",
            "Epoch: 0036 loss_train: 0.5456 acc_train: 0.7190 acc_val: 0.7175\n",
            "Epoch: 0037 loss_train: 0.5412 acc_train: 0.7259 acc_val: 0.7133\n",
            "Epoch: 0038 loss_train: 0.5404 acc_train: 0.7238 acc_val: 0.7205\n",
            "Epoch: 0039 loss_train: 0.5384 acc_train: 0.7234 acc_val: 0.7180\n",
            "Epoch: 0040 loss_train: 0.5343 acc_train: 0.7284 acc_val: 0.7205\n",
            "Epoch: 0041 loss_train: 0.5360 acc_train: 0.7306 acc_val: 0.7197\n",
            "Epoch: 0042 loss_train: 0.5319 acc_train: 0.7299 acc_val: 0.7218\n",
            "Epoch: 0043 loss_train: 0.5304 acc_train: 0.7300 acc_val: 0.7226\n",
            "Epoch: 0044 loss_train: 0.5315 acc_train: 0.7277 acc_val: 0.7222\n",
            "Epoch: 0045 loss_train: 0.5287 acc_train: 0.7374 acc_val: 0.7247\n",
            "Epoch: 0046 loss_train: 0.5258 acc_train: 0.7328 acc_val: 0.7142\n",
            "Epoch: 0047 loss_train: 0.5266 acc_train: 0.7369 acc_val: 0.7209\n",
            "Epoch: 0048 loss_train: 0.5272 acc_train: 0.7327 acc_val: 0.7150\n",
            "Epoch: 0049 loss_train: 0.5232 acc_train: 0.7402 acc_val: 0.7222\n",
            "Epoch: 0050 loss_train: 0.5215 acc_train: 0.7354 acc_val: 0.7167\n",
            "Epoch: 0051 loss_train: 0.5182 acc_train: 0.7400 acc_val: 0.7209\n",
            "Epoch: 0052 loss_train: 0.5158 acc_train: 0.7424 acc_val: 0.7239\n",
            "Epoch: 0053 loss_train: 0.5139 acc_train: 0.7429 acc_val: 0.7175\n",
            "Epoch: 0054 loss_train: 0.5141 acc_train: 0.7447 acc_val: 0.7277\n",
            "Epoch: 0055 loss_train: 0.5149 acc_train: 0.7424 acc_val: 0.7218\n",
            "Epoch: 0056 loss_train: 0.5107 acc_train: 0.7450 acc_val: 0.7252\n",
            "Epoch: 0057 loss_train: 0.5124 acc_train: 0.7431 acc_val: 0.7243\n",
            "Epoch: 0058 loss_train: 0.5068 acc_train: 0.7472 acc_val: 0.7277\n",
            "Epoch: 0059 loss_train: 0.5064 acc_train: 0.7489 acc_val: 0.7222\n",
            "Epoch: 0060 loss_train: 0.5064 acc_train: 0.7455 acc_val: 0.7349\n",
            "Epoch: 0061 loss_train: 0.5054 acc_train: 0.7474 acc_val: 0.7328\n",
            "Epoch: 0062 loss_train: 0.5042 acc_train: 0.7486 acc_val: 0.7298\n",
            "Epoch: 0063 loss_train: 0.5039 acc_train: 0.7513 acc_val: 0.7332\n",
            "Epoch: 0064 loss_train: 0.4989 acc_train: 0.7505 acc_val: 0.7285\n",
            "Epoch: 0065 loss_train: 0.4975 acc_train: 0.7582 acc_val: 0.7323\n",
            "Epoch: 0066 loss_train: 0.4955 acc_train: 0.7549 acc_val: 0.7336\n",
            "Epoch: 0067 loss_train: 0.4969 acc_train: 0.7528 acc_val: 0.7319\n",
            "Epoch: 0068 loss_train: 0.4951 acc_train: 0.7553 acc_val: 0.7336\n",
            "Epoch: 0069 loss_train: 0.4897 acc_train: 0.7596 acc_val: 0.7349\n",
            "Epoch: 0070 loss_train: 0.4919 acc_train: 0.7573 acc_val: 0.7311\n",
            "Epoch: 0071 loss_train: 0.4888 acc_train: 0.7597 acc_val: 0.7362\n",
            "Epoch: 0072 loss_train: 0.4863 acc_train: 0.7565 acc_val: 0.7429\n",
            "Epoch: 0073 loss_train: 0.4852 acc_train: 0.7602 acc_val: 0.7425\n",
            "Epoch: 0074 loss_train: 0.4846 acc_train: 0.7588 acc_val: 0.7332\n",
            "Epoch: 0075 loss_train: 0.4819 acc_train: 0.7646 acc_val: 0.7416\n",
            "Epoch: 0076 loss_train: 0.4810 acc_train: 0.7631 acc_val: 0.7370\n",
            "Epoch: 0077 loss_train: 0.4802 acc_train: 0.7633 acc_val: 0.7425\n",
            "Epoch: 0078 loss_train: 0.4808 acc_train: 0.7648 acc_val: 0.7383\n",
            "Epoch: 0079 loss_train: 0.4766 acc_train: 0.7669 acc_val: 0.7408\n",
            "Epoch: 0080 loss_train: 0.4776 acc_train: 0.7649 acc_val: 0.7433\n",
            "Epoch: 0081 loss_train: 0.4739 acc_train: 0.7734 acc_val: 0.7315\n",
            "Epoch: 0082 loss_train: 0.4722 acc_train: 0.7665 acc_val: 0.7412\n",
            "Epoch: 0083 loss_train: 0.4717 acc_train: 0.7742 acc_val: 0.7476\n",
            "Epoch: 0084 loss_train: 0.4727 acc_train: 0.7701 acc_val: 0.7370\n",
            "Epoch: 0085 loss_train: 0.4747 acc_train: 0.7708 acc_val: 0.7366\n",
            "Epoch: 0086 loss_train: 0.4676 acc_train: 0.7685 acc_val: 0.7366\n",
            "Epoch: 0087 loss_train: 0.4636 acc_train: 0.7730 acc_val: 0.7357\n",
            "Epoch: 0088 loss_train: 0.4681 acc_train: 0.7717 acc_val: 0.7404\n",
            "Epoch: 0089 loss_train: 0.4656 acc_train: 0.7725 acc_val: 0.7378\n",
            "Epoch: 0090 loss_train: 0.4636 acc_train: 0.7757 acc_val: 0.7408\n",
            "Epoch: 0091 loss_train: 0.4619 acc_train: 0.7745 acc_val: 0.7400\n",
            "Epoch: 0092 loss_train: 0.4651 acc_train: 0.7729 acc_val: 0.7429\n",
            "Epoch: 0093 loss_train: 0.4614 acc_train: 0.7777 acc_val: 0.7467\n",
            "Epoch: 0094 loss_train: 0.4544 acc_train: 0.7791 acc_val: 0.7421\n",
            "Epoch: 0095 loss_train: 0.4550 acc_train: 0.7780 acc_val: 0.7438\n",
            "Epoch: 0096 loss_train: 0.4611 acc_train: 0.7753 acc_val: 0.7412\n",
            "Epoch: 0097 loss_train: 0.4531 acc_train: 0.7774 acc_val: 0.7391\n",
            "Epoch: 0098 loss_train: 0.4492 acc_train: 0.7799 acc_val: 0.7421\n",
            "Epoch: 0099 loss_train: 0.4538 acc_train: 0.7801 acc_val: 0.7408\n",
            "Epoch: 0100 loss_train: 0.4502 acc_train: 0.7809 acc_val: 0.7395\n",
            "Test set results: test_loss= 0.5333 test_accuracy= 0.7430 f1_score= 0.7606 mcc= 0.4834\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.7430, dtype=torch.float64),\n",
              " tensor(0.5333, grad_fn=<NllLossBackward0>),\n",
              " <function sklearn.metrics._classification.f1_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')>)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAT (Graph Attention Networks) - replace RGCN with GAT"
      ],
      "metadata": {
        "id": "f3PMJzVJezkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GAT(nn.Module):\n",
        "    def __init__(self,description_size=768,tweet_size=768,numerical_properties_size=6,categorical_properties_size=3,embedding_dimension=128,dropout=0.3):\n",
        "        super(GAT, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.linear_relu_descriptioncription=nn.Sequential(\n",
        "            nn.Linear(description_size,int(embedding_dimension/4)),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_relu_tweet=nn.Sequential(\n",
        "            nn.Linear(tweet_size,int(embedding_dimension/4)),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_relu_numerical_properties=nn.Sequential(\n",
        "            nn.Linear(numerical_properties_size,int(embedding_dimension/4)),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_relu_categorical_properties=nn.Sequential(\n",
        "            nn.Linear(categorical_properties_size,int(embedding_dimension/4)),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        \n",
        "        self.linear_relu_input=nn.Sequential(\n",
        "            nn.Linear(embedding_dimension,embedding_dimension),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_relu_output1=nn.Sequential(\n",
        "            nn.Linear(embedding_dimension,embedding_dimension),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.linear_output2=nn.Linear(embedding_dimension,2)\n",
        "        \n",
        "        self.gat1=GATConv(embedding_dimension,int(embedding_dimension/4),heads=4)\n",
        "        self.gat2=GATConv(embedding_dimension,embedding_dimension)\n",
        "        \n",
        "    def forward(self,des,tweet,numerical_properties,categorical_properties,edge_index,edge_type):\n",
        "        d=self.linear_relu_descriptioncription(des)\n",
        "        t=self.linear_relu_tweet(tweet)\n",
        "        n=self.linear_relu_numerical_properties(numerical_properties)\n",
        "        c=self.linear_relu_categorical_properties(categorical_properties)\n",
        "        x=torch.cat((d,t,n,c),dim=1)\n",
        "        \n",
        "        x=self.linear_relu_input(x)\n",
        "        x=self.gat1(x,edge_index)\n",
        "        x=F.dropout(x,p=self.dropout,training=self.training)\n",
        "        x=self.gat2(x,edge_index)\n",
        "        x=self.linear_relu_output1(x)\n",
        "        x=self.linear_output2(x)\n",
        "            \n",
        "        return x"
      ],
      "metadata": {
        "id": "s4wU5MFvsH2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GAT(numerical_properties_size=6,categorical_properties_size=3,embedding_dimension=128).to(device)\n",
        "loss=nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train(epoch)\n",
        "    \n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FZJ0rtMsNzE",
        "outputId": "70961760-a7a7-4515-ef80-9f92b8f24f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 loss_train: 0.8150 acc_train: 0.4569 acc_val: 0.4609\n",
            "Epoch: 0002 loss_train: 0.8101 acc_train: 0.5633 acc_val: 0.5526\n",
            "Epoch: 0003 loss_train: 0.6796 acc_train: 0.5641 acc_val: 0.5543\n",
            "Epoch: 0004 loss_train: 0.7297 acc_train: 0.5011 acc_val: 0.5150\n",
            "Epoch: 0005 loss_train: 0.6854 acc_train: 0.5737 acc_val: 0.5510\n",
            "Epoch: 0006 loss_train: 0.6466 acc_train: 0.6223 acc_val: 0.6182\n",
            "Epoch: 0007 loss_train: 0.6585 acc_train: 0.6034 acc_val: 0.5915\n",
            "Epoch: 0008 loss_train: 0.6640 acc_train: 0.6091 acc_val: 0.5894\n",
            "Epoch: 0009 loss_train: 0.6395 acc_train: 0.6212 acc_val: 0.6199\n",
            "Epoch: 0010 loss_train: 0.6239 acc_train: 0.6508 acc_val: 0.6423\n",
            "Epoch: 0011 loss_train: 0.6279 acc_train: 0.6698 acc_val: 0.6643\n",
            "Epoch: 0012 loss_train: 0.6329 acc_train: 0.6639 acc_val: 0.6588\n",
            "Epoch: 0013 loss_train: 0.6217 acc_train: 0.6737 acc_val: 0.6584\n",
            "Epoch: 0014 loss_train: 0.6074 acc_train: 0.6793 acc_val: 0.6702\n",
            "Epoch: 0015 loss_train: 0.6019 acc_train: 0.6625 acc_val: 0.6571\n",
            "Epoch: 0016 loss_train: 0.6096 acc_train: 0.6523 acc_val: 0.6550\n",
            "Epoch: 0017 loss_train: 0.6057 acc_train: 0.6613 acc_val: 0.6541\n",
            "Epoch: 0018 loss_train: 0.5986 acc_train: 0.6748 acc_val: 0.6702\n",
            "Epoch: 0019 loss_train: 0.5942 acc_train: 0.6782 acc_val: 0.6829\n",
            "Epoch: 0020 loss_train: 0.5923 acc_train: 0.6916 acc_val: 0.6837\n",
            "Epoch: 0021 loss_train: 0.5919 acc_train: 0.6933 acc_val: 0.6951\n",
            "Epoch: 0022 loss_train: 0.5869 acc_train: 0.6982 acc_val: 0.6947\n",
            "Epoch: 0023 loss_train: 0.5815 acc_train: 0.6921 acc_val: 0.6884\n",
            "Epoch: 0024 loss_train: 0.5808 acc_train: 0.6892 acc_val: 0.6808\n",
            "Epoch: 0025 loss_train: 0.5764 acc_train: 0.6911 acc_val: 0.6858\n",
            "Epoch: 0026 loss_train: 0.5734 acc_train: 0.6965 acc_val: 0.6943\n",
            "Epoch: 0027 loss_train: 0.5676 acc_train: 0.7033 acc_val: 0.7006\n",
            "Epoch: 0028 loss_train: 0.5666 acc_train: 0.7078 acc_val: 0.7006\n",
            "Epoch: 0029 loss_train: 0.5663 acc_train: 0.7092 acc_val: 0.7015\n",
            "Epoch: 0030 loss_train: 0.5630 acc_train: 0.7150 acc_val: 0.6964\n",
            "Epoch: 0031 loss_train: 0.5563 acc_train: 0.7130 acc_val: 0.7011\n",
            "Epoch: 0032 loss_train: 0.5558 acc_train: 0.7189 acc_val: 0.7061\n",
            "Epoch: 0033 loss_train: 0.5546 acc_train: 0.7202 acc_val: 0.7082\n",
            "Epoch: 0034 loss_train: 0.5521 acc_train: 0.7216 acc_val: 0.7049\n",
            "Epoch: 0035 loss_train: 0.5466 acc_train: 0.7234 acc_val: 0.7137\n",
            "Epoch: 0036 loss_train: 0.5479 acc_train: 0.7267 acc_val: 0.7121\n",
            "Epoch: 0037 loss_train: 0.5420 acc_train: 0.7253 acc_val: 0.7133\n",
            "Epoch: 0038 loss_train: 0.5381 acc_train: 0.7298 acc_val: 0.7082\n",
            "Epoch: 0039 loss_train: 0.5370 acc_train: 0.7311 acc_val: 0.7137\n",
            "Epoch: 0040 loss_train: 0.5328 acc_train: 0.7351 acc_val: 0.7104\n",
            "Epoch: 0041 loss_train: 0.5305 acc_train: 0.7367 acc_val: 0.7184\n",
            "Epoch: 0042 loss_train: 0.5307 acc_train: 0.7375 acc_val: 0.7184\n",
            "Epoch: 0043 loss_train: 0.5300 acc_train: 0.7347 acc_val: 0.7163\n",
            "Epoch: 0044 loss_train: 0.5259 acc_train: 0.7363 acc_val: 0.7197\n",
            "Epoch: 0045 loss_train: 0.5238 acc_train: 0.7404 acc_val: 0.7137\n",
            "Epoch: 0046 loss_train: 0.5224 acc_train: 0.7374 acc_val: 0.7205\n",
            "Epoch: 0047 loss_train: 0.5187 acc_train: 0.7443 acc_val: 0.7226\n",
            "Epoch: 0048 loss_train: 0.5229 acc_train: 0.7458 acc_val: 0.7235\n",
            "Epoch: 0049 loss_train: 0.5174 acc_train: 0.7457 acc_val: 0.7226\n",
            "Epoch: 0050 loss_train: 0.5170 acc_train: 0.7446 acc_val: 0.7256\n",
            "Epoch: 0051 loss_train: 0.5144 acc_train: 0.7468 acc_val: 0.7256\n",
            "Epoch: 0052 loss_train: 0.5120 acc_train: 0.7491 acc_val: 0.7218\n",
            "Epoch: 0053 loss_train: 0.5101 acc_train: 0.7498 acc_val: 0.7273\n",
            "Epoch: 0054 loss_train: 0.5098 acc_train: 0.7516 acc_val: 0.7319\n",
            "Epoch: 0055 loss_train: 0.5049 acc_train: 0.7496 acc_val: 0.7247\n",
            "Epoch: 0056 loss_train: 0.5035 acc_train: 0.7536 acc_val: 0.7302\n",
            "Epoch: 0057 loss_train: 0.5025 acc_train: 0.7578 acc_val: 0.7353\n",
            "Epoch: 0058 loss_train: 0.5005 acc_train: 0.7597 acc_val: 0.7353\n",
            "Epoch: 0059 loss_train: 0.4978 acc_train: 0.7609 acc_val: 0.7387\n",
            "Epoch: 0060 loss_train: 0.4978 acc_train: 0.7601 acc_val: 0.7345\n",
            "Epoch: 0061 loss_train: 0.4931 acc_train: 0.7607 acc_val: 0.7357\n",
            "Epoch: 0062 loss_train: 0.4933 acc_train: 0.7669 acc_val: 0.7404\n",
            "Epoch: 0063 loss_train: 0.4931 acc_train: 0.7659 acc_val: 0.7400\n",
            "Epoch: 0064 loss_train: 0.4885 acc_train: 0.7688 acc_val: 0.7362\n",
            "Epoch: 0065 loss_train: 0.4891 acc_train: 0.7718 acc_val: 0.7383\n",
            "Epoch: 0066 loss_train: 0.4858 acc_train: 0.7705 acc_val: 0.7412\n",
            "Epoch: 0067 loss_train: 0.4871 acc_train: 0.7676 acc_val: 0.7421\n",
            "Epoch: 0068 loss_train: 0.4867 acc_train: 0.7704 acc_val: 0.7357\n",
            "Epoch: 0069 loss_train: 0.4811 acc_train: 0.7754 acc_val: 0.7476\n",
            "Epoch: 0070 loss_train: 0.4812 acc_train: 0.7708 acc_val: 0.7450\n",
            "Epoch: 0071 loss_train: 0.4770 acc_train: 0.7764 acc_val: 0.7429\n",
            "Epoch: 0072 loss_train: 0.4771 acc_train: 0.7759 acc_val: 0.7488\n",
            "Epoch: 0073 loss_train: 0.4766 acc_train: 0.7752 acc_val: 0.7526\n",
            "Epoch: 0074 loss_train: 0.4726 acc_train: 0.7766 acc_val: 0.7505\n",
            "Epoch: 0075 loss_train: 0.4688 acc_train: 0.7795 acc_val: 0.7510\n",
            "Epoch: 0076 loss_train: 0.4681 acc_train: 0.7806 acc_val: 0.7476\n",
            "Epoch: 0077 loss_train: 0.4667 acc_train: 0.7824 acc_val: 0.7569\n",
            "Epoch: 0078 loss_train: 0.4648 acc_train: 0.7832 acc_val: 0.7531\n",
            "Epoch: 0079 loss_train: 0.4615 acc_train: 0.7829 acc_val: 0.7586\n",
            "Epoch: 0080 loss_train: 0.4583 acc_train: 0.7855 acc_val: 0.7560\n",
            "Epoch: 0081 loss_train: 0.4567 acc_train: 0.7869 acc_val: 0.7556\n",
            "Epoch: 0082 loss_train: 0.4569 acc_train: 0.7905 acc_val: 0.7607\n",
            "Epoch: 0083 loss_train: 0.4549 acc_train: 0.7898 acc_val: 0.7526\n",
            "Epoch: 0084 loss_train: 0.4500 acc_train: 0.7920 acc_val: 0.7586\n",
            "Epoch: 0085 loss_train: 0.4465 acc_train: 0.7967 acc_val: 0.7632\n",
            "Epoch: 0086 loss_train: 0.4455 acc_train: 0.7933 acc_val: 0.7649\n",
            "Epoch: 0087 loss_train: 0.4446 acc_train: 0.7971 acc_val: 0.7641\n",
            "Epoch: 0088 loss_train: 0.4430 acc_train: 0.7971 acc_val: 0.7632\n",
            "Epoch: 0089 loss_train: 0.4398 acc_train: 0.7986 acc_val: 0.7696\n",
            "Epoch: 0090 loss_train: 0.4349 acc_train: 0.7998 acc_val: 0.7615\n",
            "Epoch: 0091 loss_train: 0.4369 acc_train: 0.8030 acc_val: 0.7624\n",
            "Epoch: 0092 loss_train: 0.4343 acc_train: 0.8041 acc_val: 0.7603\n",
            "Epoch: 0093 loss_train: 0.4289 acc_train: 0.8037 acc_val: 0.7696\n",
            "Epoch: 0094 loss_train: 0.4273 acc_train: 0.8066 acc_val: 0.7734\n",
            "Epoch: 0095 loss_train: 0.4250 acc_train: 0.8076 acc_val: 0.7717\n",
            "Epoch: 0096 loss_train: 0.4239 acc_train: 0.8097 acc_val: 0.7738\n",
            "Epoch: 0097 loss_train: 0.4242 acc_train: 0.8072 acc_val: 0.7641\n",
            "Epoch: 0098 loss_train: 0.4216 acc_train: 0.8074 acc_val: 0.7700\n",
            "Epoch: 0099 loss_train: 0.4276 acc_train: 0.8094 acc_val: 0.7742\n",
            "Epoch: 0100 loss_train: 0.4247 acc_train: 0.8050 acc_val: 0.7700\n",
            "Test set results: test_loss= 0.4917 test_accuracy= 0.7777 f1_score= 0.8053 mcc= 0.5520\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.7777, dtype=torch.float64),\n",
              " tensor(0.4917, grad_fn=<NllLossBackward0>),\n",
              " <function sklearn.metrics._classification.f1_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')>)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graphs & Results"
      ],
      "metadata": {
        "id": "lf7HiEH9LHrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px"
      ],
      "metadata": {
        "id": "qdqf27UqLMVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(root+'results.csv')\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "0BPPynnJLNJX",
        "outputId": "3574453e-b746-4922-a4f4-07c7574d937f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Method  loss_train  acc_train  acc_val  test_loss  test_accuracy  f1_score  \\\n",
              "0   RGCN      0.2420     0.8973   0.8567     0.3437         0.8580    0.8721   \n",
              "1  RGCN2      0.4194     0.8095   0.7383     0.5685         0.7320    0.7681   \n",
              "2  RGCN3      0.4382     0.7987   0.7810     0.4959         0.7701    0.7824   \n",
              "3  RGCN4      0.5255     0.7333   0.7108     0.5451         0.7287    0.7775   \n",
              "4  RGCN5      0.4214     0.8088   0.7928     0.4055         0.8157    0.8541   \n",
              "5  RGCN6      0.3403     0.8564   0.7886     0.5357         0.7675    0.7850   \n",
              "6  RGCN7      0.3990     0.8166   0.7928     0.4037         0.8183    0.8538   \n",
              "7    GCN      0.4502     0.7809   0.7395     0.5333         0.7430    0.7606   \n",
              "8    GAT      0.4247     0.8050   0.7700     0.4917         0.7777    0.8053   \n",
              "\n",
              "      mcc  \n",
              "0  0.7139  \n",
              "1  0.4590  \n",
              "2  0.5397  \n",
              "3  0.4598  \n",
              "4  0.6663  \n",
              "5  0.5320  \n",
              "6  0.6621  \n",
              "7  0.4834  \n",
              "8  0.5520  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-401e736b-0ef8-4ad6-b268-822775208769\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Method</th>\n",
              "      <th>loss_train</th>\n",
              "      <th>acc_train</th>\n",
              "      <th>acc_val</th>\n",
              "      <th>test_loss</th>\n",
              "      <th>test_accuracy</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>mcc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RGCN</td>\n",
              "      <td>0.2420</td>\n",
              "      <td>0.8973</td>\n",
              "      <td>0.8567</td>\n",
              "      <td>0.3437</td>\n",
              "      <td>0.8580</td>\n",
              "      <td>0.8721</td>\n",
              "      <td>0.7139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RGCN2</td>\n",
              "      <td>0.4194</td>\n",
              "      <td>0.8095</td>\n",
              "      <td>0.7383</td>\n",
              "      <td>0.5685</td>\n",
              "      <td>0.7320</td>\n",
              "      <td>0.7681</td>\n",
              "      <td>0.4590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RGCN3</td>\n",
              "      <td>0.4382</td>\n",
              "      <td>0.7987</td>\n",
              "      <td>0.7810</td>\n",
              "      <td>0.4959</td>\n",
              "      <td>0.7701</td>\n",
              "      <td>0.7824</td>\n",
              "      <td>0.5397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RGCN4</td>\n",
              "      <td>0.5255</td>\n",
              "      <td>0.7333</td>\n",
              "      <td>0.7108</td>\n",
              "      <td>0.5451</td>\n",
              "      <td>0.7287</td>\n",
              "      <td>0.7775</td>\n",
              "      <td>0.4598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RGCN5</td>\n",
              "      <td>0.4214</td>\n",
              "      <td>0.8088</td>\n",
              "      <td>0.7928</td>\n",
              "      <td>0.4055</td>\n",
              "      <td>0.8157</td>\n",
              "      <td>0.8541</td>\n",
              "      <td>0.6663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RGCN6</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.8564</td>\n",
              "      <td>0.7886</td>\n",
              "      <td>0.5357</td>\n",
              "      <td>0.7675</td>\n",
              "      <td>0.7850</td>\n",
              "      <td>0.5320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RGCN7</td>\n",
              "      <td>0.3990</td>\n",
              "      <td>0.8166</td>\n",
              "      <td>0.7928</td>\n",
              "      <td>0.4037</td>\n",
              "      <td>0.8183</td>\n",
              "      <td>0.8538</td>\n",
              "      <td>0.6621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>GCN</td>\n",
              "      <td>0.4502</td>\n",
              "      <td>0.7809</td>\n",
              "      <td>0.7395</td>\n",
              "      <td>0.5333</td>\n",
              "      <td>0.7430</td>\n",
              "      <td>0.7606</td>\n",
              "      <td>0.4834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>GAT</td>\n",
              "      <td>0.4247</td>\n",
              "      <td>0.8050</td>\n",
              "      <td>0.7700</td>\n",
              "      <td>0.4917</td>\n",
              "      <td>0.7777</td>\n",
              "      <td>0.8053</td>\n",
              "      <td>0.5520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-401e736b-0ef8-4ad6-b268-822775208769')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-401e736b-0ef8-4ad6-b268-822775208769 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-401e736b-0ef8-4ad6-b268-822775208769');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test accuracy bar graph\n",
        "\n",
        "fig = px.bar(df, x='Method', y='test_accuracy',\n",
        "             hover_data=['acc_train', 'f1_score', 'mcc'], color='test_accuracy',\n",
        "             labels={'Test Accuracy'}, height=400)\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "yRvT5iswLorC",
        "outputId": "5764ab73-f182-4f40-db0a-2e0ba496b6b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"ff7c9696-0951-421d-9731-52a5c097dccd\" class=\"plotly-graph-div\" style=\"height:400px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ff7c9696-0951-421d-9731-52a5c097dccd\")) {                    Plotly.newPlot(                        \"ff7c9696-0951-421d-9731-52a5c097dccd\",                        [{\"alignmentgroup\":\"True\",\"customdata\":[[0.8973,0.8721,0.7139],[0.8095,0.7681,0.459],[0.7987,0.7824,0.5397],[0.7333,0.7775,0.4598],[0.8088,0.8541,0.6663],[0.8564,0.785,0.532],[0.8166,0.8538,0.6621],[0.7809,0.7606,0.4834],[0.805,0.8053,0.552]],\"hovertemplate\":\"Method=%{x}<br>test_accuracy=%{marker.color}<br>acc_train=%{customdata[0]}<br>f1_score=%{customdata[1]}<br>mcc=%{customdata[2]}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":[0.858,0.732,0.7701,0.7287,0.8157,0.7675,0.8183,0.743,0.7777],\"coloraxis\":\"coloraxis\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"RGCN\",\"RGCN2\",\"RGCN3\",\"RGCN4\",\"RGCN5\",\"RGCN6\",\"RGCN7\",\"GCN\",\"GAT\"],\"xaxis\":\"x\",\"y\":[0.858,0.732,0.7701,0.7287,0.8157,0.7675,0.8183,0.743,0.7777],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Method\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"test_accuracy\"}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"test_accuracy\"}},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"height\":400},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ff7c9696-0951-421d-9731-52a5c097dccd');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MCC bar graph\n",
        "fig = px.bar(df, y='mcc', x='Method', text_auto='.4f',\n",
        "            title=\"MCC\")\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "dioAc5GjLeFe",
        "outputId": "1aada269-92e7-45b6-b4f4-fb1095dddcf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"efe8c2d9-e29e-4113-8daf-596729c3ec2e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"efe8c2d9-e29e-4113-8daf-596729c3ec2e\")) {                    Plotly.newPlot(                        \"efe8c2d9-e29e-4113-8daf-596729c3ec2e\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Method=%{x}<br>mcc=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"texttemplate\":\"%{y:.4f}\",\"x\":[\"RGCN\",\"RGCN2\",\"RGCN3\",\"RGCN4\",\"RGCN5\",\"RGCN6\",\"RGCN7\",\"GCN\",\"GAT\"],\"xaxis\":\"x\",\"y\":[0.7139,0.459,0.5397,0.4598,0.6663,0.532,0.6621,0.4834,0.552],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Method\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"mcc\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"MCC\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('efe8c2d9-e29e-4113-8daf-596729c3ec2e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# f1 score bar graph\n",
        "fig = px.bar(df, y='f1_score', x='Method', text_auto='.4f',\n",
        "            title=\"f1-score\")\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "0lI1cqg_Li62",
        "outputId": "dd65d686-a065-40c5-aa21-fe5a1ed649da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"04be4d1f-e690-4735-a926-3f02e1c0634e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"04be4d1f-e690-4735-a926-3f02e1c0634e\")) {                    Plotly.newPlot(                        \"04be4d1f-e690-4735-a926-3f02e1c0634e\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Method=%{x}<br>f1_score=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"texttemplate\":\"%{y:.4f}\",\"x\":[\"RGCN\",\"RGCN2\",\"RGCN3\",\"RGCN4\",\"RGCN5\",\"RGCN6\",\"RGCN7\",\"GCN\",\"GAT\"],\"xaxis\":\"x\",\"y\":[0.8721,0.7681,0.7824,0.7775,0.8541,0.785,0.8538,0.7606,0.8053],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Method\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"f1_score\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"f1-score\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('04be4d1f-e690-4735-a926-3f02e1c0634e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}